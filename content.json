{"meta":{"title":"点击积累","subtitle":"每天进步一点点","description":"","author":"guozhe","url":"https://nijixucai.github.io","root":"/"},"pages":[],"posts":[{"title":"linux/linux常用命令记录","slug":"linux/linux常用命令记录","date":"2020-12-15T09:40:43.965Z","updated":"2020-12-15T09:41:31.760Z","comments":true,"path":"2020/12/15/linux/linux常用命令记录/","link":"","permalink":"https://nijixucai.github.io/2020/12/15/linux/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"","text":"tar 解压 1tar -xzvf 压缩","categories":[],"tags":[]},{"title":"blockchain/6Hyperledger-Frbirc测试环境错误记录","slug":"blockchain/6Hyperledger-Frbirc测试环境错误记录","date":"2020-12-15T08:00:42.955Z","updated":"2020-12-15T08:02:49.033Z","comments":true,"path":"2020/12/15/blockchain/6Hyperledger-Frbirc测试环境错误记录/","link":"","permalink":"https://nijixucai.github.io/2020/12/15/blockchain/6Hyperledger-Frbirc%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Hyperledger-Frbirc测试环境错误记录 在部署chaincode（./network.sh deployCC）的时候报错如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/fabric-samples/test-network$ ./network.sh deployCCdeploying chaincode on channel 'mychannel'executing with the following- CHANNEL_NAME: mychannel- CC_NAME: basic- CC_SRC_PATH: NA- CC_SRC_LANGUAGE: go- CC_VERSION: 1.0- CC_SEQUENCE: 1- CC_END_POLICY: NA- CC_COLL_CONFIG: NA- CC_INIT_FCN: NA- DELAY: 3- MAX_RETRY: 5- VERBOSE: falseDetermining the path to the chaincodeasset-transfer-basicVendoring Go dependencies at ../asset-transfer-basic/chaincode-go/~/code/open-source/blockchain/hyperledger/fabric-samples/asset-transfer-basic/chaincode-go ~/code/open-source/blockchain/hyperledger/fabric-samples/test-network~/code/open-source/blockchain/hyperledger/fabric-samples/test-networkFinished vendoring Go dependencies+ peer lifecycle chaincode package basic.tar.gz --path ../asset-transfer-basic/chaincode-go/ --lang golang --label basic_1.0+ res=0Chaincode is packagedInstalling chaincode on peer0.org1...Using organization 1+ peer lifecycle chaincode install basic.tar.gz+ res=1Error: failed to retrieve endorser client for install: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceededUsage: peer lifecycle chaincode install [flags]Flags: --connectionProfile string The fully qualified path to the connection profile that provides the necessary connection information for the network. Note: currently only supported for providing peer connection information -h, --help help for install --peerAddresses stringArray The addresses of the peers to connect to --tlsRootCertFiles stringArray If TLS is enabled, the paths to the TLS root cert files of the peers to connect to. The order and number of certs specified should match the --peerAddresses flagGlobal Flags: --cafile string Path to file containing PEM-encoded trusted certificate(s) for the ordering endpoint --certfile string Path to file containing PEM-encoded X509 public key to use for mutual TLS communication with the orderer endpoint --clientauth Use mutual TLS when communicating with the orderer endpoint --connTimeout duration Timeout for client to connect (default 3s) --keyfile string Path to file containing PEM-encoded private key to use for mutual TLS communication with the orderer endpoint -o, --orderer string Ordering service endpoint --ordererTLSHostnameOverride string The hostname override to use when validating the TLS connection to the orderer --tls Use TLS when communicating with the orderer endpoint --tlsHandshakeTimeShift duration The amount of time to shift backwards for certificate expiration checks during TLS handshakes with the orderer endpointChaincode installation on peer0.org1 has failedDeploying chaincode failed","categories":[],"tags":[]},{"title":"language/java/线程池无法捕获线程的异常踩坑复盘","slug":"language/java/线程池无法捕获线程的异常踩坑复盘","date":"2020-12-15T02:24:42.056Z","updated":"2020-12-15T02:24:42.056Z","comments":true,"path":"2020/12/15/language/java/线程池无法捕获线程的异常踩坑复盘/","link":"","permalink":"https://nijixucai.github.io/2020/12/15/language/java/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%97%A0%E6%B3%95%E6%8D%95%E8%8E%B7%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BC%82%E5%B8%B8%E8%B8%A9%E5%9D%91%E5%A4%8D%E7%9B%98/","excerpt":"","text":"问题描述 需求信息 最近在工作中有个需求，先在A服务页面增加一条数据，然后去B服务查询此数据的详细信息 解决方案 为了使A服务的新增数据接口快速响应，在查询B服务数据详情的地方使用了线程池异步查询与更新。 问题现象 在验证时发现数据库中的数据字段不全，经分析缺少的都是需要从B服务查询并更新的字段 初步定位 猜测应该是查询B服务时出了一些异常，而由于不规范使用线程池导致异常没有抛出，直接打到了控制台，故A服务的日志系统并看不到错误日志。 问题解决 查询B服务数据详情时暂时去掉使用线程池，改为同步调用 增加容错定时任务，定时查询需要从B服务获取缺失字段的数据进行更新 上线后观察，新增的数据不再有部分字段缺失的情况；问题解决。 问题复盘 A服务线程池的使用 线程池定义 12345/** * 查询B服务数据详情的线程池 */private static final ExecutorService executorService = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadFactoryBuilder().setNameFormat(\"queryDataDetail-%d\").build()); 线程池使用 12345678910@Override@Transactional(rollbackFor = Exception.class)public void add(String contract) &#123; // 0、检查合同必须不存在 checkIfExist(contract); // 1、保存合同数据 Entity entity = saveData(contract); // 2、从B服务查询缺失信息 executorService.execute(() -&gt; queryDataDetail(entity));&#125; 如此使用有何问题 我重新写了一个测试方法如下： 1、定义一个会一直抛异常的方法 1234567891011121314/** * 引入SystemOutRule，监听程序日志输出 */@Rulepublic SystemOutRule systemOutRule = new SystemOutRule().enableLog();/** * 引入SystemOutRule，监听程序日志输出 */private String runWithException() &#123; Thread thread = Thread.currentThread(); log.info(\"thread is &#123;&#125;\", thread); log.info(\"eh=&#123;&#125;\", thread.getUncaughtExceptionHandler()); throw new NicaiException(\"出错啦！\");&#125; 2、使用线程池调用上面的方法 12345678@Testpublic void run() throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(this::runWithException); TimeUnit.MILLISECONDS.sleep(100L); // 断言程序打印的日志不包含“出错啦！” Assert.assertFalse(systemOutRule.getLog().contains(\"出错啦！\"));&#125; 3、上面的单测断言是成功的，那么异常跑哪里去了？上面的单测在控制台的输出如下： 4、可以看出上面的异常信息是直接输出到了控制台，而不是由程序输出到控制台，主要原因是主程序没有捕获到此异常导致的。（具体原因还没有深入） 如何解决线程池的异常捕获问题 上面的测试可以说明到为什么日志里面查不到错误日志，那么如何捕获线程里的异常呢？ 方法1:使用UncaughtExceptionHandler 1、在创建线程池的时候，设置传入的ThreadFactory的UncaughtExceptionHandler属性，此UncaughtExceptionHandler会处理线程中的异常；下面的例子我直接打印了出来异常原因和异常栈。 12345678910@Testpublic void runWithUncaughtExceptionHandler() throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool( new ThreadFactoryBuilder() .setUncaughtExceptionHandler((t, e) -&gt; log.info(\"UncaughtExceptionHandler caught, error_message=&#123;&#125;\", e.getMessage(), e)) .build()); executorService.execute(this::runWithException); TimeUnit.MILLISECONDS.sleep(100L); Assert.assertTrue(systemOutRule.getLog().contains(\"出错啦！\"));&#125; 2、上面的单测运行结果如下：（可以和上面的运行结果进行比对） 3、从上面的运行结果可以看出异常信息是由程序捕获后再输出出来，这样就不会导致查不到异常日志了。 方法2:使用guava扩展的FutureCallback 1、guava对jdk的线程做了一些扩展，其中一个就是FutureCallback，使用方法如下： 123456789101112131415161718@Testpublic void runWithGuavaThreadPool() throws InterruptedException &#123; ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool()); ListenableFuture&lt;String&gt; listenableFuture = executorService.submit(this::runWithException); Futures.addCallback(listenableFuture, new FutureCallback&lt;String&gt;() &#123; @Override public void onSuccess(String result) &#123; log.info(\"success! result = &#123;&#125;\", result); &#125; @Override public void onFailure(Throwable t) &#123; log.error(\"guava FutureCallback caught, error_message=&#123;&#125;\", t.getMessage(), t); &#125; &#125;, executorService); TimeUnit.MILLISECONDS.sleep(100L); Assert.assertTrue(systemOutRule.getLog().contains(\"出错啦！\"));&#125; 2、上面的单测运行结果如下： 问题总结 1、通过上面的测试，优化A服务的线程池定义，使之在遇到异常时能够正常被捕获，能输出，方便问题定位；补偿定时任务也能对第一次查询异常进行容错，保证数据能够同步过来。 1234567/** * 查询B服务数据详情的线程池 */private static final ExecutorService executorService = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadFactoryBuilder() .setUncaughtExceptionHandler((t, e) -&gt; log.error(\"查询数据详情的线程池异常,error_message=&#123;&#125;\", e.getMessage(), e)) .setNameFormat(\"queryDataDetail-%d\").build()); 2、当然此问题更深层的问题还没有完全解答 为什么线程里的异常不会被捕获？ UncaughtExceptionHandler的运行原理是什么？ Guava的FutureCallback是如何运行的？ 3、测试代码源码地址","categories":[],"tags":[]},{"title":"language/java/使用redis自增特性创建唯一id生成器","slug":"language/java/使用redis自增特性创建唯一id生成器","date":"2020-12-15T02:24:42.055Z","updated":"2020-12-15T02:24:42.056Z","comments":true,"path":"2020/12/15/language/java/使用redis自增特性创建唯一id生成器/","link":"","permalink":"https://nijixucai.github.io/2020/12/15/language/java/%E4%BD%BF%E7%94%A8redis%E8%87%AA%E5%A2%9E%E7%89%B9%E6%80%A7%E5%88%9B%E5%BB%BA%E5%94%AF%E4%B8%80id%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"","text":"需求说明 产品要求实现一个订单编号，此编号规则如下 订单编号规则： “字母” + “日期” + “自增ID” 订单编号举例 比如业务A，在2020-08-04日有三个订单，那么订单编号如下： A202008040001 A202008040002 A202008040003 比如业务A，在2020-08-05日有4个订单，那么订单编号如下： A202008050001 A202008050002 A202008050003 A202008050003 通过上面的例子可以看到，后面的“自增ID”每天都会从1开始增加，在一个分布式系统中，要做到每天从1开始不重复并且自增的效果；想到的第一个实现方案就是redis的Incr命令（Redis Incr 命令将 key 中储存的数字值增一）。 需求实现 配置redis 依赖redis相关jar包 因为此模块继承了spring-boot-starter-parent，所以不需要指定版本 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; 编写配置redis的config 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.nicai.config;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisClusterConfiguration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.StringRedisTemplate;/** * redis集群配置 * * @author guozhe * @date 2020/08/04 */@Configuration@EnableConfigurationProperties(RedisProperties.class)public class RedisClusterConfig &#123; private final RedisProperties redisProperties; public RedisClusterConfig(RedisProperties redisProperties) &#123; this.redisProperties = redisProperties; &#125; /** * Thread-safe factory of Redis connections配置 * * @return factory of Redis */ @Bean public RedisConnectionFactory redisConnectionFactory() &#123; RedisClusterConfiguration redisClusterConfiguration = new RedisClusterConfiguration(redisProperties.getCluster().getNodes()); redisClusterConfiguration.setPassword(redisProperties.getPassword()); return new JedisConnectionFactory(redisClusterConfiguration); &#125; /** * 创建String类型的redis模板 * * @param redisConnectionFactory factory of Redis * @return String-focused extension of RedisTemplate */ @Bean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; StringRedisTemplate template = new StringRedisTemplate(redisConnectionFactory); template.afterPropertiesSet(); return template; &#125;&#125; 如果是配置范型的RedisTemplate，需要设置值的序列化规则为：StringRedisSerializer，原因可以参考此文章：Spring Boot中使用RedisTemplate优雅的操作Redis，并且解决RedisTemplate泛型注入失败的问题 测试redis的config代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.nicai.config;import com.yuanfeng.accounting.BaseAdminSpringTest;import com.yuanfeng.accounting.Constants;import lombok.extern.slf4j.Slf4j;import org.junit.Assert;import org.junit.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.core.ValueOperations;import java.util.concurrent.TimeUnit;/** * @author guozhe * @date 2020/08/04 */@Slf4j@RunWith(SpringRunner.class)@SpringBootTest(classes = AdminApplication.class)public class RedisClusterConfigTest &#123; private static final String TEST_KEY = Constants.REDIS_KEY_PREFIX + \"test:hello\"; private static final String TEST_VALUE = \"world\"; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void testStringRedisTemplateGetAndSet() &#123; stringRedisTemplate.opsForValue().set(TEST_KEY, TEST_VALUE); String value = stringRedisTemplate.opsForValue().get(TEST_KEY); Assert.assertEquals(TEST_VALUE, value); stringRedisTemplate.delete(TEST_KEY); Assert.assertNull(stringRedisTemplate.opsForValue().get(TEST_KEY)); &#125; @Test public void testIncr() &#123; String key = TEST_KEY; ValueOperations&lt;String, String&gt; valueOperations = stringRedisTemplate.opsForValue(); valueOperations.set(key, \"1\", 24, TimeUnit.HOURS); String initValue = valueOperations.get(key); log.info(\"key=&#123;&#125;, init value=&#123;&#125;\", key, initValue); Assert.assertEquals(\"1\", initValue); Long increment = valueOperations.increment(key); log.info(\"key=&#123;&#125;, after increment=&#123;&#125;\", key, increment); Assert.assertEquals(Long.valueOf(2), increment); stringRedisTemplate.delete(key); Assert.assertNull(valueOperations.get(key)); &#125;&#125; 基于redis编写唯一ID生成服务 添加抽象的唯一id生成服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196package com.nicai.service;import cn.hutool.core.util.BooleanUtil;import com.alibaba.fastjson.JSON;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.StringRedisTemplate;import java.util.Objects;import java.util.Optional;import java.util.concurrent.TimeUnit;/** * 分布式ID生成服务 * * @author guozhe * @date 2020/08/04 */@Slf4jpublic abstract class AbstractRedisDistributedIDGenerateService&lt;T extends AbstractRedisDistributedIDGenerateService.Context&gt; &#123; /** * 初始化key时的默认值 */ private static final long DEFAULT_VALUE = 0; protected final StringRedisTemplate redisTemplate; public AbstractRedisDistributedIDGenerateService(StringRedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; /** * 获取下一个ID，直接从redis中获取自增后的值； * * @return 下一个ID, 如果redis出现异常则返回null，请使用者自行处理 */ public final Optional&lt;Long&gt; nextId() &#123; // 从redis中获取自增id Long id = incr(getKey()); return Objects.isNull(id) ? Optional.empty() : Optional.of(id); &#125; /** * 获取下一个ID，根据传入的上下文和redis中自增后的值最终组装成下一个ID； * 获取之后会交给子类检查此ID是否重复，如果重复会从子类中获取最新的ID，然后更新redis中的值 * * @param context 拼装id时需要的上下文 * @return 下一个ID */ public final String nextId(T context) &#123; Optional&lt;Long&gt; id = nextId(); // 如果可以从redis中获取值，则说明redis服务正常，需要判重；否则直接从数据库中获取下一个id String nextId = id.isPresent() ? ifDuplicatedThenUpdate(context, assemblyNextId(context, id.get())) : getNewIdFromDbAndUpdateRedis(context, null); if (log.isDebugEnabled()) &#123; log.debug(\"context=&#123;&#125;,redisIncrId=&#123;&#125; nextId=&#123;&#125;\", JSON.toJSONString(context), id, nextId); &#125; return nextId; &#125; /** * 检查获取到的ID是否重复 * 如果重复则说明由于redis的一些原因导致的重复，返回最新的redis中应该存在的值 * * @param nextId 下一个ID * @return 如果当前ID没有重复，则返回null，否则如果重复了则返回redis中应该有的值 */ protected abstract boolean checkIfDuplicated(String nextId); /** * 从数据库获取下一个id * * @param duplicatedId 重复的id，此入参可能为null，子类需要自己处理 * @return 数据库获取下一个id */ protected abstract Long maxIdFromDatabase(String duplicatedId); /** * 子类根据redis当前的值自行组装最终的ID * * @param context 上下文 * @param redisValue redis当前的值 * @return 最终的ID */ protected abstract String assemblyNextId(T context, Long redisValue); /** * 获取redis自增的key * * @return redis自增的key */ protected abstract String getKey(); /** * 调用redis的自增方法 * 如果key不存在则先设置key，再调用自增方法 * * @param key 需要自增的key * @return 自增之后的值，如果redis出现异常则返回null */ Long incr(String key) &#123; Long increment = null; try &#123; // 先检查redis中是否有key,如果没有,先设置key并且设置过期时间 if (BooleanUtil.isFalse(redisTemplate.hasKey(key))) &#123; initOrUpdateValue(key, getKeyInitValue()); &#125; increment = redisTemplate.opsForValue().increment(key); &#125; catch (Exception e) &#123; log.error(\"调用redis的自增方法异常，error_message=&#123;&#125;\", e.getMessage(), e); &#125; log.debug(\"key = &#123;&#125;, increment=&#123;&#125;\", key, increment); return increment; &#125; /** * 获取初始化key时的value值，默认是0，自增之后id从1开始； * 如果子类想从其他数字开始则自己覆盖此方法即可 * * @return 初始化key时的value值 */ protected long getKeyInitValue() &#123; return DEFAULT_VALUE; &#125; /** * 获取key的超时时间，单位是小时，由子类设置 * * @return 超时时间，单位小时 */ protected abstract long getTimeOutHours(); /** * 判断是否重复，如果重复则从别的渠道（由子类自己决定从哪个渠道）更新 * * @param context 拼装id时需要的上下文 * @param nextId 下一个id * @return 如果重复则返回新的nextId，否则返回入参传入的nextId */ private String ifDuplicatedThenUpdate(T context, String nextId) &#123; // 判断是否重复，如果重复则从数据库中获取，否则直接返回当前值 return checkIfDuplicated(nextId) ? getNewIdFromDbAndUpdateRedis(context, nextId) : nextId; &#125; /** * 从数据库获取新id并更新redis中的值 * * @param context 拼装id时需要的上下文 * @param nextId 下一个id * @return 根据数据库的id获得的新id */ private String getNewIdFromDbAndUpdateRedis(T context, String nextId) &#123; Long maxIdFromDatabase = maxIdFromDatabase(nextId); String newId = assemblyNextId(context, maxIdFromDatabase); log.warn(\"nextId=&#123;&#125; 在数据库中已经存在，maxIdFromDatabase=&#123;&#125; 重新获取新的newId=&#123;&#125;\", nextId, maxIdFromDatabase, newId); initOrUpdateValue(getKey(), maxIdFromDatabase); return newId; &#125; /** * 初始化或者更新redis中的自增的值 * * @param key redis中的key * @param value 需要设置的值 */ private void initOrUpdateValue(String key, Long value) &#123; try &#123; redisTemplate.opsForValue().set(key, String.valueOf(value), getTimeOutHours(), TimeUnit.HOURS); &#125; catch (Exception e) &#123; log.error(\"设置redis值异常，value=&#123;&#125; error_message=&#123;&#125;\", value, e.getMessage(), e); &#125; &#125; /** * 上下文；子类自己定义上下文，然后根据上下文的数据来最终组装ID */ public interface Context &#123; &#125; /** * 凭证编号上下文 */ @Data @NoArgsConstructor @AllArgsConstructor public static class AContext implements Context &#123; /** * 业务类型 */ private String businessType; &#125;&#125; 添加一个A服务的唯一id生成服务实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.nicai.service.impl;import cn.hutool.core.date.DatePattern;import cn.hutool.core.date.DateUtil;import cn.hutool.core.util.StrUtil;import com.yuanfeng.accounting.Constants;import com.yuanfeng.accounting.dao.ManualVoucherDAO;import com.yuanfeng.accounting.entity.ManualVoucherEntity;import com.yuanfeng.accounting.exception.AccountingException;import com.yuanfeng.accounting.service.AbstractRedisDistributedIDGenerateService;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import java.util.List;import java.util.Objects;import java.util.Optional;/** * 分布式唯一ID生成-A实现类 * 编号规则：用途+日期+自增ID，如：A202007310001；A202007310002；A202008070001； * * @author guozhe * @date 2020/08/04 */@Slf4j@Servicepublic class DistributedIDGenerateServiceAImpl extends AbstractRedisDistributedIDGenerateService&lt;AbstractRedisDistributedIDGenerateService.AContext&gt; &#123; /** * 业务类型 */ private static final String BUSINESS_TYPE = \"A:\"; /** * ID长度不足4位时在前面填充的字符 */ private static final char FILLED_CHAR = '0'; /** * 最后的自增ID的长度 */ private static final int INCREMENT_LENGTH = 4; /** * 过期小时数，即在24小时候过期 */ private static final int EXPIRATION_HOURS = 24; public DistributedIDGenerateServiceAImpl(StringRedisTemplate redisTemplate) &#123; super(redisTemplate); &#125; @Override protected boolean checkIfDuplicated(String nextId) &#123; return false; &#125; @Override protected Long maxIdFromDatabase(String duplicatedId) &#123; return 1L; &#125; @Override protected String assemblyNextId(VoucherNumberContext context, Long redisValue) &#123; return String.join(Constants.BLANK, context.getBusinessType(), getDatePeriod(), StrUtil.fillBefore(String.valueOf(redisValue), FILLED_CHAR, INCREMENT_LENGTH)); &#125; @Override protected String getKey() &#123; return String.join(Constants.REDIS_KEY_DELIMITER, Constants.REDIS_KEY_PREFIX, BUSINESS_TYPE, getDatePeriod()); &#125; @Override protected long getTimeOutHours() &#123; return EXPIRATION_HOURS; &#125;&#125;","categories":[],"tags":[]},{"title":"为什么我们在使用Spring的时候应该使用构造方法注入bean","slug":"language/java/为什么建议使用构造器注入而不是@Autoware","date":"2020-12-15T02:24:42.055Z","updated":"2020-12-15T02:24:42.055Z","comments":true,"path":"2020/12/15/language/java/为什么建议使用构造器注入而不是@Autoware/","link":"","permalink":"https://nijixucai.github.io/2020/12/15/language/java/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8%E6%9E%84%E9%80%A0%E5%99%A8%E6%B3%A8%E5%85%A5%E8%80%8C%E4%B8%8D%E6%98%AF@Autoware/","excerpt":"","text":"问题 对于使用Spring框架的java开发人员对下面的代码应该很熟悉： 12@Autowiredprivate HelloService helloService; 但是对于上面的代码，Sonar会提示：Remove this annotation and use constructor injection instead. 翻译成中文即：移除@Autowired注解使用构造器注入方式替代。 IntelliJ IDEA也会提示Field injection is not recommended 翻译成中文即：不推荐使用字段注入 那么他们为什么这么建议呢？ 首先我们先看一下Spring有哪些注入bean的方式 构造方法注入 set方法注入 字段注入，即@Autowired注解 如何使用这些方式 构造方法注入 在Spring4.3版本之前，我们必须要在构造方法上加@Autowired注解；在新版本中如果当前类只有一个构造方法@Autowired注解就是可选的。 只有一个构造方法示例： 123456789@Controllerpublic class ValidationController &#123; private final HelloService helloService; public ValidationController(HelloService helloService) &#123; this.helloService = helloService; &#125;&#125; 多个构造方法示例： 1234567891011121314@Controllerpublic class ValidationController &#123; private HelloService helloService; @Autowired public ValidationController(HelloService helloService) &#123; this.helloService = helloService; &#125; public ValidationController() &#123; &#125;&#125; set方法注入 这种方式Spring会找到 @Autowired 注解并且调用set方法来注入所需的依赖。 1234567891011121314@Controllerpublic class ValidationController &#123; private HelloService helloService; public HelloService getHelloService() &#123; return helloService; &#125; @Autowired public void setHelloService(HelloService helloService) &#123; this.helloService = helloService; &#125;&#125; 字段注入 通过基于字段的注入，Spring在使用@Autowired注释进行注释时，直接将所需的依赖项分配给字段。 123456@Controllerpublic class ValidationController &#123; @Autowired private HelloService helloService;&#125; 这些方式有什么优缺点 既然要移除@Autowired注解使用构造器注入方式替代，那么我们主要讨一下这些方式的优缺点。 字段注入方式的优点 相比较另外两种方式，字段注入方式的代码量更少、更整齐、更简洁 构造方法注入的优点 容易发现代码的坏味道 set方法注入和字段注入会间接违反单一职责原则。 因为在一个类依赖很多其他类的时候，如果使用构造方法注入就会发现构造方法的参数太多，这会让开发人员反思这个类真的需要这么多依赖吗？当前类是不是职责过多？ 而使用字段注入时，就会把一些例如sonar的提示屏蔽掉，让开发人员误以为这样做没有问题 可以创建不可变类 在使用构造方法注入时因为构造方法是创建依赖对象的唯一方式，这非常有助于让我们创建不可变的对象。 想象一下创建一个bean之后你可以通过set方法随意修改此类的依赖，在出现问题时是很难定位的。 @Autowired的源码有一段注释如下：Fields are injected right after construction of a bean, before any config methods are invoked. Such a config field does not have to be public. 大意是使用@Autowired注解时，bean是在构造当前的bean之后，并且在任何的其他方法调用之前注入，因此无法设置成final类型的字段。 更明显的声明所有的依赖 使用构造方法注入，在使用这个类时就会暴露给使用者说我要依赖构造方法中的类。 但是使用字段注入时，使用者其实并不知道这个类依赖了哪些类，除非我到此类中查看这个类有多少个字段是有@Autowired注解。 不方便迁移 spring实现了DI（控制反转），但并非是DI本身； 使用构造方法注入时，除了在类上面有@Service、@Component等的注解，没有其他的Spring相关的更多的注解。 使用字段注入时，除了在类上面有@Service、@Component等的注解之外又使用了Spring的@Autowired注解，如果把此类迁移到其他没有spring的环境时是完成不了注入的。 不方便测试 在使用构造方法注入时，单元测试时开发人员可以直接传入一个mock的类或者其他的任何被测试类依赖的子类； 当然我们也可以使用set方式注入一个mock的类，但是如果代码修改了新增了一个依赖，那么我们很容易忘掉在测试代码中set新增的依赖，直到运行的时候我们才会看到可能有NPE异常爆出；但是构造方法就不必有这种烦恼，因为如果新增了一个依赖，测试方法会马上编译不通过。 使用字段注入，必须依赖Spring去帮助注入依赖的类 总结 通过构造方法注入bean是我们更容易创建不可变类，代码更健壮、更具有可测试性、更容易避免NPE。","categories":[],"tags":[]},{"title":"blockchain/0区块链的学习计划","slug":"blockchain/0区块链的学习计划","date":"2020-12-11T11:04:50.000Z","updated":"2020-12-14T09:37:58.176Z","comments":true,"path":"2020/12/11/blockchain/0区块链的学习计划/","link":"","permalink":"https://nijixucai.github.io/2020/12/11/blockchain/0%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/","excerpt":"","text":"区块链的学习计划 除了这些你还需要学习什么？ X.509 TLS/SSL 分片（以太坊中有此概念、布比区块链也有） 跨链是如何实现的 国密从哪里能找到，有没有开源与标准 DeFi是什么？ 一个区块链公司需要哪些： 业务持续学习： 保理模式 承兑汇票 清分 应收账款 贴现 拆转融 ABS","categories":[],"tags":[]},{"title":"blockchain/2区块链开发框架-Corda学习总结","slug":"blockchain/2区块链开发框架-Corda学习总结","date":"2020-12-11T06:43:22.000Z","updated":"2020-12-16T06:24:22.699Z","comments":true,"path":"2020/12/11/blockchain/2区块链开发框架-Corda学习总结/","link":"","permalink":"https://nijixucai.github.io/2020/12/11/blockchain/2%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-Corda%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"0. Corda资料整理 官网 油管频道 Corda中文文档 开发文档 Corda中文社区 Stack Overflow讨论区, corda标签 Corda Training 1. Corda是什么？ Corda是为企业构建的开源区块链/分布式账本帐平台；Corda使企业可以使用智能合约在严格的隐私下直接进行交易，从而降低交易和记录保存成本，并简化业务运营。 Corda不会定期将需要确认的交易分批处理再分成块之后一次性确认。相反，Corda会实时确认每笔交易。 1.0 Corda有哪些概念 1.0.1 网络 一个Corda网络由运行着Corda和CorDapps的节点构成的 不同的节点间的沟通是点对点的，不依赖于全局广播 每个节点都可以使用一个数字证书来将真实世界中的法律身份和网络身份相关联 这个网络是一个需要许可的网络，需要从网络维护者那里申请一个数字证书来获得访问权限 1.0.2 账本 每个账本是针对于每一个节点的 对于账本上的共享事实，共享的两方（或多方）总是能够保证存在他们自己的账本中的事实是完全一致的 在 Corda 中是 没有唯一的中心化存储的数据 的。每个节点维护着一个独立的数据库，其中包含了所知道的事实。所以每个 peer 只能够看到账本中的事实中的一部分，没有节点能够知道所有的内容。 1.0.3 States State 代表的是存在账本上的事实 State 通过将原来的 State 变为历史记录然后添加一条新版本的 state 的方式来对 state 进行更新 每个节点都有一个 vault 来存储该节点所有相关的 States 1.0.3.0 State 顺序 个共享的事实的生命周期是可以通过 state 顺序 来体现。当一个 state 需要更新的时候，我们会创建一个代表新的 state 的新版本的 state，然后将原来的那个 state 标注为历史版本。 1.0.3.1 Vault Corda 网络中的每一个节点都维护着一个 vault - 它是一个数据库，其中跟踪了所有 states 的当前以及历史的 states 数据，以及跟它有关的数据： 1.0.3.2 参考 states 并不是所有的 states 都需要被使用他们的节点来更新的。对于参数数据的情况，有一种常见的模式，一方创建了参考数据，这些数据会被其他方使用（但是不会被更新）。对于这种情况，states 中包含的参考数据被称为 “参考 states”。 1.0.4 Transactions Transaction 是关于更新账本的提议；（个人理解：更准确的说应该是更新账本上的某些states的提议） 一个 transaction 提议只能在满足以下条件的时候才会被提交： 它不包含“双花” 它是合约有效的 它需要被所有相关方提供签名 Corda 使用 UTXO (未消费的 transaction output) 模型来使账本上的每条 state 都不可更改。对于账本上数据的变更都是通过使用 transaction 的方式来做的，就是将 0 条或多条已经存在的账本 states 变为历史记录（inputs），然后再新增0条或多条新的账本 states （outputs）。交易代表了 state 顺序中的一个单独的链接。 **个人理解：**这一点和比特币很像，不同点是比特币的交易只需要支付的人的签名，而这里的transaction需要所有人相关人的签名 一个 transaction 中可以包含任何数量任何类型的 inputs 和 outputs： 可以包含多种类型的 state（cash, bonds） 可以是 issuances 类型（有0个input）或者 exists 类型（有0个 output） 可以合并或拆分可替换的资产（比如把一个 $2 的 state 和 $5 的 state 合并为 $7 的 cash state） Transaction 是 原子性操作，一个 transaction 里边的所有 changes 必须要全部执行，或者一个也不会执行。 有两种基本类型的 transactions： Notary-change transactions（用来变更 state 的 notary - 查看 Notaries） General transactions（其他任何类型的 transaction） 1.0.4.1 交易链 一个新的 transaction 的 output state 在账本中应该是还不存在的，所以需要提出 transaction 的一方来创建。但是 transaction 中包含的 input 应该是在账本中已经存在的，应该是前一个 transaction 添加进去的 output。所以我们需要在新的 transaction 中引用这些已经存在的记录。 这些 Input state 的引用包含两部分(个人理解：与比特币的交易链一样)： 创建这个 input 的 transaction 的 hash 这个 input 所指的前一个 transaction 带来的 output state 在 output list 中的位置或者索引值 1.0.4.2 提交交易 初始的时候，一个 transaction 仅仅是一个更新账本的 提议。它表示了经过这次更新后账本的新的状态： 为了成为真正的一笔交易，transaction 必须要获得所有 要求的签名*（查看下边的 *command）。每一个要求的签名者会将签名附加在 transaction 上来表示他们已经同意了这次更新： 如果得到了所有需要的签名，这个 transaction 就会被提交了： 一旦提交就意味着： Transaction 的 input 被标注为历史记录，并且不能再被之后的 transactions 使用了 Transaction 的 output 变为账本上的当前状态的一部分 1.0.4.3 交易的有效性 每一个被要求的签名方应该只有在满足以下两个条件的时候才应该提供签名： Transaction 是有效的：对于当前的 transaction 提案以及产生当前提案的 Input 相关的所有以前的所有 transactions 的链条中： Transaction 应该获得所有相关方的数字签名 Transaction 是 合约有效 的 Transaction 唯一性：本次 transaction 提案要消费的 inputs 没有被任何已经存在的其他的已提交的 transaction 消费过 1.0.4.4 参考 states 正如 States 所描述的，一些 states 需要被其他的 input 或者 output states 的合约代码所引用，但是不需要被修改/消费。这就需要参考 states。当一个 state 被添加到一笔交易的参考 states 列表中，而不是 inputs 或者 outputs 列表的时候，那么它就被作为 参考 state。在常规的 states 和参考 states 间有两点区别： 交易的节点指定的 notary 会检查参考 state 是不是当前的。然而，当包含他们的交易被提交到账本的时候，参考 states 是不会被消费的。 对于参考 states 的合约代码也不会被包含他们的交易所执行。 1.0.4.5 其他的交易组件 就像 input states 和 output states 一样，transactions 还可能会包含下边的组件： Commands Attachments Timestamps Notary 比如一个交易中，Alice 使用 £5 的现金向 Bob 支付了一个 IOU 的 £5。该笔交易包含了两个附件，并且只能够在 notary pool 在指定的时间窗内收到该笔交易的时候被 NotaryClusterA 进行公证，看起来像下边这样： 1.0.4.5.1 Commands 翻译视频讲解Corda 核心概念 - Commands Commands是什么？ Commands 是一些动词（verbs） Commands 将 transaction 进行参数化（parameterise），这样除了从 State 中能够获取的信息外，commands 又能提供了更多的一些信息 Commands 也提示（hint）了 transaction 的意图（intent） Commands 也可能包含通过 Oracle Service 提供的数据（off-ledger data） 一些 Commands 典型的例子： 发布（issue）新的 State 到账本上 交换（transfer）资产到账本中的另一方 付钱（pay）给账本中的另一方 偿还（redeem）一笔资产并结束/清除代表该资产的state 尝试（exercise）一个选项 option 履行（settle）一个义务来递交一个资产 如何知道一个 transaction 都需要谁来提供签名呢？我们会把一个公钥列表关联至一个 command，来说明都谁需要对这个 command 提供签名。 一个 command中会包含一个公钥列表（public key list），通过这个列表就知道了都会涉及哪些人来确认/签名该 state transaction 在 transaction中，input 和 output states 经常会被按照类别分组（还可能根据其他的条件进行分组） 每一组 state 都需要有一个 command 1.0.4.5.2 Attachments 有些时候，我们会有一些数据可以在不同的 transactions 中被重用。比如： 一个公共假期的 calendar 支持的法律文档 一个货币代码的表格 针对这些情况，我们使用附件。一个 transaction 可以通过 hash 引用 0 个或者多个附件。这些附件是 ZIP/JAR 文件，可以包含任何内容。这些附件中信息可以用来验证 transaction 的有效性。 1.0.4.5.3 Time-window 一些时候，我们希望一个交易仅仅在一个指定的时间点被批准执行。例如： 在一个指定的日期之后执行一个选项 一个债券只能在它的过期日期前被赎回 在这些情况下，我们给 transaction 添加一个 time-window。time-windows 制定了交易会在哪个时间点被提交。 1.0.4.5.4 Notary **个人理解：**为了在issuance/genesis 交易中提供公证证明的，证明此交易的合法性。 1.0.5 Contracts **个人理解：**与以太坊的智能合约类似 一个有效的 transaction 必须要被它的所有 input 和 output states中的 contract 接受 Contracts 需要使用 JVM 编程语言编写（java 或者 kotlin） Contract 的执行是一定要有一个确定性结果的，并且它对于一个 transaction 的接受是仅仅基于 transaction 的内容 1.0.5.1 Transaction 验证 一个 transaction 仅仅当被所有要求的签名方提供了签名之后才会被认为是有效的。但是，除了获得到所有人的签名之后，还必须要满足 合约有效 才会被最终认为有效。 合约有效 的定义包含以下几点： 每个 state 都指定了一个 合约 类别 合约将交易(transaction)作为输入，并根据合约规则说明该交易是否有效 仅当every input state和** every output state **的合约都认为其有效时，交易(transaction)才有效 我们可以用下图来描述这个关系： 合约代码可以用任何JVM语言编写，并可以使用该语言的全部功能，包括： 检查 inputs，outputs，commands 的数量，时间，附件 检查这些组件中的任何一个的内容 循环构造，变量分配，函数调用，辅助方法等 将一些类似的 states 分组来验证（比如对于所有的现金 state 的组合定义一个规则） 一个 transaction 如果不是合约有效的话，是不会被视为一个对账本的有效更新，也就不可能被提交至账本。通过这种方式，合同对state随时间的变化施加了规则，这些规则与所需签名者签署给定交易的意愿无关。 1.0.5.2 The contract sandbox **个人理解：**为了保证验证的结果不根据外部的条件而改变，Corda提供了一个沙箱，以防止代码引入可能会造成不确定性结果的外部库 Deterministic Corda Modules Transaction 验证必须是 一个确定性的结果： 在一个确定的transaction提议中，一个 contract 必须总是接受 或者 总是拒绝。比如 transaction 是否有效不能够取决于你在什么时间做的 verify 或者是基于某一方具有的信息量的多少来决定是有效的还是无效的。这是一个很重要的条件来确保网络上的相关节点能够在这个对账本的更新的操作达成共识。 1.0.5.3 Contract 的局限性 因为 contract 没有办法访问到外部的信息，它只能检查 transaction 内部的有效性，比如它不能够检查确认当前这个 transaction 是不是已经同其他相关方达成了共识取得了其他方的确认。 所以在各方提供最终的签名确认之前，各方应该对transaction 的内容进行检查来确定他们是否同意这个对账本的更新，即使这个 transaction 是合约有效的。任何一方都没有义务因为transaction是是合约有效而提供签名。比如他们可能不愿意去提供一个巨额的借款，或者可能不会同意购买一个资产花费的钱的金额。 1.0.5.4 Oracles 有时，交易有效性将取决于某些外部信息，例如汇率。在这些情况下，需要一个oracle。有关更多详细信息，请参见Oracle。 1.0.5.5 Legal prose 每一个合约也会引用一个 legal prose 文档，这个文档中定义了合约中规定的内容，legal prose 也会被传统的法律系统所接受。这个文档会在发生法律纠纷的时候被用来进行判定依据。 1.0.6 Flows Flows 使同意更新账本的流程变得自动化 节点之间的沟通只能够在这些 Flows 的上下文中发生，并且是点对点的 内置的 flows 提供了常用的一些任务 Corda 网络使用点对点的消息传输而不是全局广播。也就是说协调一个关于账本的更新需要网络上的参与者明确的指定需要发送什么信息，发送给谁，按照什么顺序发送。 1.0.6.1 Flow 框架 一个 flow 是一系列有顺序的步骤来告诉一个节点应该如何实现一个指定的账本更新，比如发行一个资产或者结算一笔交易。 下边是一个上边图片所描述的简单账本更新所涉及到的顺序的流程： 1.0.6.2 运行 flows 一旦一个业务流程被封装在了一个 flow 中并且在节点中作为 CorDapp 的一部分被安装好之后，节点的所有者可以在任何时间通过使用一个 RPC call 来告诉节点开始这个业务流程。Flow 将所有的网络，I/O 和并发问题都抽象了出来，这个节点 owner 就不需要关注这些了。 节点上所有的动作都是发生在这些 flows 的上下文上的。与 contract 不同，flows 不是在 sandbox 里执行的，也就是说节点可以在执行一个 flow 的过程中来进行一些动作比如 networking，I/O 或者随机地使用一些资源。 1.0.6.3 节点内部通信 节点间是通过在不同的 flows间传递消息来进行沟通的。每个节点有0个或者多个注册的 flow classes 来回复另外个一个单独的 flow 的消息。 假设 Alice 是网络中的一个节点，并且她希望同 Bob（网络中的另一个节点） 一起同意一次账本的更新。为了跟 Bob 进行沟通， Alice 必须： 开始一个 Bob 已经注册过的 flow Alice 在这个 flow 的上下文中给 Bob 发送一个消息 Bob 会启动它注册的这个 conterparty flow 连接已经建立起来了，Alice 和 Bob 就可以像 flow 步骤中描述的那样来回地沟通关于一个更新账本的改动并且最终达成一致。 1.0.6.4 Subflows Flows 可以通过在另外一个 flow 的上下文中开始一个新的 flow 作为一个子流程的方式被组成。作为子流程被启动的 Flow 被称为 subflow。父 flow 需要等待所有的 subflow 完成后才会继续运行。 1.0.6.5 Flow 类库 Corda 对于一些常规的任务都提供了一套代码库（API: Flows），所以开发者就不需要自己去定义这些常见流程背后的逻辑了，比如： 公正和记录一个 transaction 从相关节点搜集签名 验证交易链 1.0.6.6 并发 Flow 框架允许节点可以同时运行多个 flows。这些 flows 可能由于节点的重启甚至升级会持续几天。 这个可以通过在 flow 变成阻塞的状态的时候，将 flows 序列化到硬盘中的方式来实现（比如他们在等待 I/O 或者是网络的调用）。出现这种情况的时候，节点不会等待这个阻塞状态的 flow变成非阻塞的状态，而会立即运行其他的 flow，只会在稍后返回到原来这个阻塞的flow。 1.0.7 consensus(共识) 为了交易能够被提交，transaction 必须要同时满足有效性和 唯一性的共识 有效性共识需要 transaction 和 它的所有依赖都是合约有效的 唯一性共识可以避免“双花” 1.0.7.1 两种类型的共识 判断一个交易的提案是否是一次有效的账本更新要达到两种类型的共识： 有效性共识：这给是交易所要求的签名者在提供他们签名之前去校验的 唯一性共识：这个只会被 notary service 去验证 1.0.7.1.1 有效性共识 有效性共识是关于验证下边所描述的条件对于提交的 transaction 和生成该该 transaction 的 inputs 的交易链中的每次 transaction 都必须要满足： Transaction 中的每个 input 和 output 的 contracts 所接受 Transaction 得到了所有要求的签名 仅仅检查交易提案本身信息是不够的。我们还需要检查跟产生当前这个 transaction 的 inputs 有关的所有以前的 transaction 链。 这个被称作 walking the chain。假设，例如网络中的一个节点提交了一个交换债券的一笔交易。我们只有了解下边的情况才能确保这个债券的交换是有效的： 这个债券应该是由中心银行发行的，而且应该是在一次有效的发行交易中 关于这个债券的后续交易记录也应该都是有效的 确保两点都满足的唯一方式就是查看整个交易链。我们可以用下图表示： 当确认一个交易提案的时候，给定的一方可能没有它需要验证的交易链上的所有交易信息。这种情况下，他可以向交易的提出方索要缺少的那部分交易。交易的提出方应该永远会有整个的交易链信息，因为他们应该在验证之前的交易中已经获取了相关的交易链信息。 1.0.7.1.2 唯一性共识 设想一下 Bob 持有有效的由中央银行发行的 $1,000,000 现金 state。Bob 可以创建两个交易提案： 一笔交易要跟 Charlie 用这 $1,000,000 交换 £800,000 一笔交易要跟 Dan 用这 $1,000,000 交换 €900,000 这会是一个问题，因为尽管这两笔交易都可以通过有效性共识，但是 Bob 确实现了一次“双花 double spend” 他的美元来获得了两倍价值的 GBP 和 EUR。我们可以用下图表示这个流程： 为了避免这样的问题发生，一个有效的交易提案同时也要满足唯一性共识。唯一性共识要求一个 transaction 的 input 不能被任何其他的 transaction 消费掉过。 当一个交易中的一个或多个 inputs 已经被其他的交易消费掉的情况，通常被称为 双花，那么相关的交易应该被视为无效的交易。 唯一性共识是由 notaries 提供的。查看 Notaries 了解更多详细信息。 1.0.8 Notaries Notary 集群避免 “双花” Notary 集群也可以是时间戳授权。如果一笔交易包含一个 time-window，那么它只能在这个 time-window 内被公证 Notary 集群也可以可选地用来验证交易，在这种情况下他们被称为 “用于验证” 的 notaries，相对于 “非验证” 的 notaries 一个网络中可以有多个 notaries，每一个 notary 运行一个不同的共识算法 1.0.8.1 概览 一个 notary 集群 是一个网络服务，通过证明一个给定的交易的 input 是没有被其他的交易消费过的方式提供了 唯一性共识。 当被要求为一笔交易进行公证的时候，一个 notary 集群会进行下边两种操作中的一种： 如果对于给定的交易中的 input，没有任何其他的交易已经消费该 input 的时候，会提供签名 拒绝这笔交易并且标明产生了双花的情况 通过这样做，notary 集群就在系统中提供了一个终结点。在最终获得 notary 集群的签名之前，交易各方并不能确定交易的有效性。但是当收到了 notary 集群的签名之后，我们可以确认的是，交易中的 Input 是没有被其他任何的交易所消费过的。因此公证（notarisation）在系统里是最后的一步。 每个 state 都会有一个指定的 notary 集群，而且一个 notary 集群也只会去公正那些 input 指定它为 notary 集群的 transaction。 1.0.8.2 共识算法 Corda 拥有一套 “可插拔” 的共识，允许 notary 集群根据不同的需求（私有化、扩展性、法律系统的兼容性和算法的便捷性）来选择一种共识算法。 特别的，notary 集群可能含有下边的不同： 结构： 一个 notary 集群可能是一个单独的网络节点，或者是互相信任的节点集群，或者是互不信任的节点集群 共识算法： 一个 notary 集群可能会选择运行一个高速，高信任的算法（比如 RAFT），或者一个低速低信任的算法（比如 BFT），又或者是任何其他的选择的共识算法 1.0.8.3 验证 一个 notary 集群还需要选择是否在提交之前通过验证每个 transaction 的有效性来提供这种 有效性共识 服务。为了做出这个选择，他们需要面对下边的取舍问题： 如果一个 transaction 没有 被验证了正确与否（非验证 notary），那么这就增加了 “denial of state” 袭击的风险，指的就是某个节点知道这是一个不正确的 transaction 会消费到一些 states，然后该节点还是把这个 transaction 发送给 notary 集群，但是 notary 如果不进行正确性验证的话，会把这个 state 变为历史记录被消费掉，这显然是不正确的 如果 transaction 已经 被验证了正确与否（验证 notary），notary 需要查看该 transaction 的全部内容以及它的所有依赖。这就向 notary 暴露了一些潜在的隐私数据。 当我们考量这些取舍的时候，有一个后续观点需要始终要考虑的。对于非验证模式，Corda 的控制的数据分布模型意味着未被消费的 states 不会被大面积的共享。另外， Corda 的 permissioned network 也意味着 notary 能够存储造成 “denial of state” transaction 的一方的身份信息，这就允许能够在账本外去解决掉这个袭击。 对于验证模式，对于匿名的使用，使用新生成的公钥而不是使用法律的标识来标记一笔交易的各方也限制了 notary 集群能够看到的信息。 1.0.8.4 数据的可视性 下边是关于哪些特殊的交易组件必须要暴露给每种类型的 notary 的一个总结： Transaction components Validating Non-validating Input states Fully visible References only [1] Output states Fully visible Hidden Commands (with signer identities) Fully visible Hidden Attachments Fully visible Hidden Time window Fully visible Fully visible Notary identity Fully visible Fully visible Signatures Fully visible Hidden 两种类型的 notaries 都会记录调用方的身份信息：公钥以及 X.500 唯一的名字。 1.0.8.5 多个 Notaries 每个 Corda 网络可以存在多个 notary 集群，每个 notary 集群可能会运行一套不同的共识算法。这会带来以下的好处： 隐私性 - 我们可以在同一个网络中同时拥有验证和非验证的 notary 集群，每个集群运行着不同的算法。这就允许节点针对每个 transaction 来选择更喜欢的不同的 notary。 负载平衡 - 将 transaction 的工作分发给多个 notary 集群可以提高平台整体的交易吞吐量 低延迟 - 通过选择物理上离交易方最近的 notary 集群来获得最小化的延迟 1.0.8.6 更换 notaries 一个 notary 集群只有当它是这个 transaction 里的所有 input states 指定的 notary 的情况下才可以提供签名。然而下边的情况可能需要换一个 state 的指定的 notary 集群，包括： 当一个 transaction 需要消费的 states 中指定了不同的 notary 集群 当一个节点因为隐私和效率的考虑希望选择一个不同的 notary 集群 当这样的 transactions 被创建之前，states 必须首先被指定到同一个 notary 集群。这可以通过一个改变 notary 的 transaction 来实现: 一个 input state output state与input state相同，但指定的notary群集已更改 如果该 transaction 不会造成“双花”，这个 input state 指定的 notary 会为该 transaction 提供签名，这种情况下，一个新的 state 会产生，它的所有属性和旧的 state相同，但是会指向一个不同的 notary 集群。 1.0.9 Vault Vault 中存储的是跟节点的所有者相关的从账本上得到的数据，以关系模型存储以方便查询和使用。 Vault 同时会追踪未消费掉的和已消费掉的 states： Unconsumed：未消费掉的 （或者未使用的） states 代表了可以用来花费的 fungible states （包括 spend-to-self 交易）以及可以用来更新的 linear states （比如对于一笔交易的生命周期）或者从一方转换给另一方。 Consumed：已消费掉的 （或者已使用的） states 代表了为了交易报表、审计和归档的目的而在账本上存储的不可更改的 state，包括进行同 app-private 数据进行关联的能力（比如客户的 notes）。 一个称为 soft locking 的功能提供了自动或者显式地预定 states 而避免同一个节点尝试同时在多笔交易中使用相同的 output 的能力。这种情况最终会被一个 notary 发现，soft locking 提供了一种能够在早期就发现这种无根据和不正确的情况的机制。Soft Locking 提供了更详细的的关于这个功能的描述。 Vault 支持管理需授权的（“on-ledger”）的数据，也可以管理 shadow（“off-ledger”）形式的数据： “On-ledger” 数据指的是指公司参与的分布式账本的state （现金、交易、）。 “Off-ledger” 数据指的是公司内部的参考数据、静态或者系统数据。 下边的图表展示了将 vault 拆分为子系统组件： 注意以下几点： Vault “On Ledger” 存储并追踪未消费掉的 state，并且在将一笔交易记录到账本的时候由节点内部进行更新（会按照成功执行了智能合约验证以及受到所有参与方的签名） Vault “Off Ledger” 存储了交易记录以外节点的所有者添加的额外的数据 Vault 对 fungible state 进行了花费（并且在将来，fungible state 的优化管理包括合并、拆分以及再发行）。 Vault 扩展代表了开发者可以编写的额外的自定义 plugin 代码，用来查询指定的自定义 contract state 属性。 客户的 “Off Ledger”（私有的存储）代表了内部的组织型数据，可能被用来跟 vault 数据进行关联来进行额外的报表或者处理。 Vault Query API 可以使用标准的 Corda RPC 和 CorDapp plugin 机制暴露给开发者。 Vault 更新 API 可以被交易记录的 flows 内部使用。 Vault 数据库 schemas 可以通过 JDBC 和自定义的 joins 和查询进行直接地访问。 1.0.10 Time-windows 如果一个 transaction 包含了一个 time-window，那么这个 transaction 只能在这个 time-window 里被提交 Notary 具有控制发生的时间的权利，当在 time-window 之外的时候，notary 可以拒绝提交 transaction Time-window 可以有开始和结束时间，或者只有两者之中的一个 1.0.10.1 分布式系统中的时间 Notary 也可以作为 时间戳的验证者，在它确认一笔交易前，需要确保这笔交易是发生在指定的时间窗里。 为了让一个时间窗有意义，它必须要在一方请求它的时候被绑定。一方可以获得一个 time-window 的签名，以此来证明有些事件是在特定时间点 之前、当时 或者 之后 发生的。然而，如果交易参与者不能够在指定的 time-window 内提交到相关的交易，它可以选择是否在未来的某个时间点将这个事实暴露出去。因此，我们需要确保 notary 或者能够在一些可容错的时间范围内对交易进行签名，或者同时进行打时间戳 和 对交易进行公证。后边的这种方式是这个模型中使用的方式。 在创建交易的一方和 notary 之间是无法实现时间的同步的。这并不仅仅是因为物理或者网络的延迟，还会因为在插入命令和获得 notary 签名之间可能会发生很多其他的步骤（比如发送交易到涉及到的其他节点，请求人工的审批等）。所以交易被发送到 notary 的时间和交易创建的时间可能会不同。 1.0.10.2 Time-windows 因为上面的原因，交易中涉及到的时间会被制定为一个时间窗，而不是一个绝对的时间。在一个分布式系统中是永远不会有 “真实的时间” 的，只有一个大概的时间。时间窗可以是开放的（比如在某个时间点后，或者某个时间点之前）或者是一个闭合的范围。 通过这种方式，我们表达了我们的想法，就是 “当前的时间” 永远都是未知的。甚至当在某个时间之前和之后都被包含的时候，交易也可能会在那个时间窗中的任何时间发生。 通过在一端创建一个关闭或者开放的范围，我们允许用以下的方式生成时间窗模型： 一笔交易在指定时间之后的某个时间发生（比如在一个终止事件之后） 一笔交易在指定时间之前的任何时间发生（比如破产事件之前） 一笔交易在指定时间区间的某个时间发生（比如在指定的某一天） 1.0.11 Oracles 一个事实（fact）可以作为 command 的一部分被添加到一个 transaction 中 一个 oracle 是一个服务，它只会为那些包含正确事实的 transaction 提供签名 很多时候 transaction 的合约有效性需要依赖一些外部的数据，比如当前的汇率是多少。如果让每个参与方给予他们对于汇率的观点来验证 transaction 的有效性的话，合约的执行就会变得没有确定性了：一些参与者可能会认为 transaction 是有效的，而其他的参与者可能认为无效。因此，在真正账本中的 state 之上就会提出一些不同的意见。 Corda 通过使用 Oracle 来解决这个问题。Oracle 是一个网络服务，可以根据要求提供包含某一事实的命令（比如在某个时间的汇率）并且将 Oracle 列为要求签名的一方。 如果一个节点希望在一个 transaction 中使用某一个事实，那么它可以提出从 Oracle 来获取该事实的一个命令。如果 Orale 认为这个事实是正确的，它会返回这个要求的命令。然后这个节点就可以把这个命令添加到 transaction 中了，然后 oracle 会为这个事实是真的提供签名。 为了隐私性的目的，Oracle 不需要能够访问交易的每个部分，他们唯一需要的信息就是看到他们内置的、跟这个 Oracle 相关的 command(s)。我们也应该提供让这些需要提供签名的 Oracle 实体能够看到这些 commands 的保证，但是不包括其他的部分。为了实现这个，我们使用过滤过的交易，是指交易的提案方使用一个内嵌的默克尔树的方式来将一些非相关的交易的部分隐藏掉。查看 Transaction tear-offs 了解关于交易如何拿掉工作的详细信息。 如果他们想为他们的服务定价，Oracles 可以选择只为那些包含服务费的交易提供签名并证明它包含的事实的有效性。 1.0.12 node（节点） Corda 中的节点指的是在网络中具有唯一标识的运行着 Corda 服务和 CorDapps 的 JVM 运行时环境。 节点对于外部世界包含两个接口： 网络层，用来同其他的节点通信 RPC，为了跟节点的所有者通信 节点的功能是通过在 plugin registry 里安装 CorDapps 方式来扩展的 1.0.12.1 节点架构 下边是节点的内部架构图： 架构中的核心元素包括： 存储数据的持久化层 同其他节点沟通的网络接口 同节点的所有者进行沟通的 RPC 接口 允许节点的 flows 来调用节点其他服务的 service hub plugin registry 用来通过安装 CorDapps 来扩展节点 1.0.12.2 持久层 持久层包含两部分： Vault，节点用来存储相关的当前和历史的 states 数据 存储服务，用来存储 transaction, attachment 和 flow checkpoints 节点的所有者可以通过使用 RPC 接口来查询节点的 storage。 1.0.12.3 网络接口 同网络中的其他节点进行沟通是节点自己来处理的，作为运行一个 flow 的一部分。节点的所有者不会直接地同网络中其他的节点进行交互。 1.0.12.4 RPC 接口 节点的所有者是通过使用 Remote Procedure Calls(RPC) 来跟节点进行交互的。关键的节点暴露的 RPC 操作可以查看 API: RPC 操作。 1.0.12.4 The service hub 在节点内部，节点可以在 flow 的执行过程中访问丰富的服务来协助更新账本。主要的服务包括： 有关网络上其他节点及其提供的服务的信息 访问 vault 和存储服务的内容 访问和生成节点的公钥私钥对 节点本身的信息 节点跟踪的当前时间 1.0.12.5 CorDapp 提供者 CorDapp 提供者是新的 CorDapps 被安装的地方，来扩展节点的行为。 节点默认会安装一些 CorDapps 来处理一些常见的任务，比如： 从合作方那边获得交易和附件信息 更新合约 向交易其他方广播同意的账本更新信息 1.0.12.6 排空节点模式 为了执行一次干净的关闭节点操作，没有正在执行的 flows 非常重要，也就是说应该没有任何的 checkpoints 被持久化。节点能够被设置为排空状态，在这个状态中： 通过 RPC 要求的启动新的 flows 的命令会被拒绝 预约的 flows 会被忽略 初始化 P2P 的会话消息将不会被处理，意味着 peers 将不能够初始化新的 flows 其他所有的活动还会照常进行，来确保正在执行的 flows 的数量在不断减少。 对于他们的数量 - 可以通过 RPC 来进行监控 - 达到0，那么就是安全的了，可以进行关闭节点的操作了。这个属性是持久的，也就是说重新启动这个节点也不会重置这个值到默认和值，并且需要一个 RPC 命令。 节点可以使用 shell 来被排空然后安全地关闭。 1.0.13 Transaction tear-offs（交易剥离） 隐藏交易组件出于隐私目的 Oracle和非验证公证人只能看到其“相关”交易组件，而不能看到完整的交易详细信息 1.0.13.1 总览 在某些情况下，交易中涉及的某些实体可能只对交易部分具有部分可见性。例如，当一个甲骨文应该签署一个交易时，它唯一需要查看的信息就是与该甲骨文命令相关的嵌入式信息。同样，非验证公证人只需要查看交易的输入状态即可。向Oracle提供任何其他交易数据将构成隐私泄漏。 为了解决这个问题，我们使用过滤交易的概念，其中交易提议者使用嵌套的默克尔树方法“剥离”Oracles/Notraries不需要的交易任何部分，然后再提交给他们进行签名。默克尔树是一种众所周知的加密方案，通常用于提供包含和数据完整性的证明。 Merkle树被广泛用于对等网络，区块链系统和git。 默克尔树的优点是，在向Oracle提交交易时被剥离的交易部分以后就无法更改，而又不会使Oracle的数字签名无效。 1.0.13.2 Transaction Merkle trees 通过将transaction拆分为叶子，从transaction中构造Merkle树，其中每个叶子包含输入，输出，命令或附件。最终的嵌套树结构还包含事务的其他字段，例如时间窗口，公证人和必需的签名者。 如下图所示，唯一需要两棵树而不是一棵树的组件类型是command，为了可视性目的，该命令分为命令数据和必需的签名者。 Corda使用每种组件类型的嵌套Merkle树。简而言之，针对每种组件类型（即输入，输出，附件）生成一个组件子树。然后，这些子树的根形成顶部的Merkle树的叶子，最后，该树的根代表交易ID。 另一个重要特征是，以每个随机数独立的方式为每个组件确定性地生成一个随机数。然后，我们使用随机数及其对应的组件来计算组件哈希，即实际的Merkle树叶。需要使用随机数来防止暴力攻击，否则可能会泄露低熵散列值（即单个单词的文本附件）的内容。 计算完叶子后，通过散列当前节点下面的哈希值的连接，以正常方式构建每棵Merkle树。 上图中的交易有三个input，两个output，两个command，一个attachment，一个notary和一个 time-window。请注意，如果树不是完整的二叉树，则将叶子填充为具有零哈希值的最接近的2的幂（因为找到sha256（x）== 0的原像是困难的计算任务）-上面标记为浅绿色。最后，根的哈希是交易的标识符，它也用于签名和验证数据完整性。叶子级别上的每次交易更改都会更改其标识符。 1.0.13.3 Hiding data 隐藏数据并提供证明它构成事务一部分的证据是通过构造部分Merkle树（或Merkle分支）来完成的。 Merkle分支是一组散列，根据叶的数据，这些散列用于计算根的散列。然后，将该哈希与整个交易的哈希进行比较，如果它们匹配，则意味着我们获得的数据属于该特定交易。 假设只有第一个命令对Oracle是可见的。我们还应该保证所有需要该Oracle签名的命令对于Oracle实体都应该是可见的，而其余部分则不可见。这是此过滤后的交易将如何在Merkle树结构中表示的方式。 向Oracle服务提供了蓝色节点和H(c2)，而省略了黑色节点。 HH(c2)是必需的，这样Oracle可以计算H(commandData)而不必看到第二条命令，但同时确保CommandData1是事务的一部分。突出显示所有签名者都是可见的，以证明没有恶意删除任何相关命令（Oracle应该看到）。此外，当前的Corda协议中还提供了子树的哈希（紫色节点）。在特殊情况下需要知道他们下面的数据，例如需要知道组件组是否为空时。 同样，如果我们想将同一交易发送给非验证notary，则应隐藏除输入状态，时间窗口和公证人信息之外的所有组件。该数据足以使公证人知道应检查哪些input statues进行双花，时间窗口是否有效以及此事务是否应由该notary公证。 1.0.14 权衡 许可的网络会更好的适合金融的 user-cases 点对点的通信允许信息是基于需要知道的原则被共享 UTXO model 允许每秒钟能够处理更多的 transactions 1.0.14.1 需要许可 vs 和不需要许可的 传统的 blockchain 是 不需要许可 的。网络中的各方都是匿名的，而且可以随时加入或离开。 不同的是， Corda 网络是 需要许可 的。网络中的每一方都有一个大家都知道的标识，这个会在同其他节点进行沟通的时候使用，并且访问网络是由一个 doorman 来控制的。这有一下的好处： 匿名的用户对于大多数跟金融有关的情况都是不适用的 知道你的合作方的身份可以允许当出现冲突的时候，可以使用已经存在的法律系统在账本外进行解决 可以不通过使用昂贵的机制（比如工作量证明 proof-of-work）来避免女巫攻击（Sybil attacks） 1.0.14.2 点对点 vs 全局广播 传统的 blockchain networks 将每一条信息广播给网络上的所有参与者。原因是： 合作方的身份是不知道的，所以一条消息需要发给网络上的所有人来确保原本需要收到这条消息的接受者能够接收到 让所有参与者知道每一个 transaction 能够允许网络防止“双花” 不好的地方是所有的参与者都能看到所有其他人的数据。这在很多的 use-cases 是无法接受的。 在 Corda 中，每条消息都会指定一个具体的合作方，而且是不会被任何其他无关方看到的。开发者能够完全掌控什么消息被发送了，发送给了谁，应该按照什么顺序发送。所以 数据是根据需要知道的原则来共享的。为了避免“双花”，我们引入了 notaries 来替换掉工作量证明（proof-of-work）。 Corda 也是用了其他的一些技术来最大化的包括网络上的隐私： Transaction 隐藏：Transactions 被结构化成不暴露 transaction 的内容就可以被数字化地签名。这个是通过使用一种叫默克尔树的数据结构来实现的。 随机化秘钥：一个 transaction 的所有参与方是通过他们的公钥进行识别的，并且针对每一个 transaction 都会生成 一个新的 keypairs。所以一个监视者无法识别出来对于一个给定 transaction 都哪些方参与了。 1.0.14.3 UTXO vs. 账户模型 Corda 使用 UTXO（Unspent Transaction Output）model。每个 transaction 都会消费一系列的已经存在的 states 然后再生成一些新的 states。 相反的一种方式是 账户 模型。在账户模型中，stateful 对象被存在账本上，transaction 会通过请求的方式来对这些对象的当前的 state 进行更新。 UTXO 模型的主要优点在于含有不同的 inputs 的 transactions 能够并行地被执行，很大程度上地增加了网络中每秒能够处理的 transactions。在账户模型中，每秒钟能够处理的 transactions 数量有限，因为对于一个给定的 object 的更新需要按照给定的顺序来执行。 1.0.14.4 代码即法律 vs. 既有的法律系统 金融体系需要在需要的时候使用传统的法律体系来解决冲突的能力。Corda 被设计用来使这个成为可能： 拥有需要准入的网络，意味着所有参与方都能够知道在每一个 transaction 中他们都在跟谁打交道 所有代码合约背后都存在有描述着合约意图行为的法律文档，这个文档可以在解决冲突的时候使用 1.0.14.5 构建 vs. 重用 任何可能的情况，Corda 会使用 已经存在的技术来让这个平台更加的健壮。比如 Corda 重用了： 用于开发CorDapps的标准JVM编程语言 已经存在的 SQL database 已经存在的 消息队列实现 1.0.15 Deterministic JVM 个人理解：为了达成共识，Corda要求所有的节点运行相同的JVM沙箱，叫做DJVM；DJVM为了让智能合约的代码每次执行的结果都相同而做了一些限制。 1.1 开发语言语言是什么？ 开发语言与智能合约的语言都是使用 JVM 编程语言编写（java 或者 kotlin） 源码使用kotlin语言编写 1.2 网络是什么样的？ 可以选择加入corda.network，Corda Network由总部位于荷兰的非营利基金会管理。 Corda Network参与者有资格投票并代表基金会董事会做出重要决定，包括网络标准，参数和政策。 或者搭建自己的私有网络，下载corda网络管理软件，需要填写信息 1.3 Corda是如何达成共识的？ 假如A发起一个交易给B转账500元，那么A需要提交一个交易（transaction）并签名；然后把交易发送给B（如果需要Notary和Oracle参与也会把need-to-know的部分发送给他们）；B验证交易没有问题（包括整个交易链、智能合约是否验证通过、是否同意当前的交易、Notary和Oracle是否签名等）就会提供签名然后提交这次交易。并把签名后的交易发送给A，A也执行相同的提交交易动作。 1.4 CorDapps是什么？ CorDapps是以plugin的形式运行在node上的“应用”；一个node可以有多个CorDapps，比如一个银行的node可以既有贷款的CorDapp，也有存款的CorDapp。 CorDapp包含state, transaction, contract和flow类。 1.5 Corda的隐私保护是怎么做的？ 1.5.1 在网络中的各节点之间的隐私保护 Corda的网络需要申请加入并且对应了现实世界中的一个合法身份，所以不可以把交易信息公开。 Corda的交易是通过一个节点发起的，除了交易涉及的其他节点知道全部的交易内容；和Oracle以及Notary知道交易的部分需要验证的内容之外，对其他节点来说是不知道这个交易的。所以在隐私性方面是比较好的。 比特币和以太坊中的身份信息与现实世界的身份是没有对应关系的，所以把所有的账户和交易信息放在互联网上也是安全的。 1.5.2 在验证双花和依赖Oracle签名时的隐私保护 Corda通过Transaction tear-offs的方式在需要Notary做唯一性校验或需要Oracle提供签名时，提供的只有need-to-know的部分，并不包含交易的所有内容，所以隐私得到了保护。 1.6 Corda交易的实时性怎么样？ Corda交易相较于比特币和以太坊来说比较实时，因为Corda不必等待挖矿只要交易被校验通过，所有人都签了名就写在了区块链上了。（以太坊和比特币需要在挖到矿之后打包很多个交易，所以实时性会差一些） 1.7 Corda中是否有以太坊中的账本的概念？ 个人理解：Corda也有账本的概念，但是Corda账本所包含的内容远比以太坊的账本（只有余额）要多；Corda的账本有很多不同类型的state，Corda只保管了当前的state和历史state，但是Corda没有一个汇总的显示余额的“账本”；应该可以在账本外记录。 1.8 Corda中账户（Accounts）是什么？ Corda中的Accounts是一个虚拟的概念，值得是一个节点的Vault的states打上标签来表示归属的账户；这个账户和节点的账户不一样，Account就像个人在银行（节点）开的账户（Account）。 1.9 Corda可以发布币吗？可以挖矿吗？ 没有数字货币，因此也不能挖矿。因为共识协议也并不是通过工作量证明完成，而是通过交易的涉及方和一些公证人和Oracle来达成共识的，所以也不需要挖矿。 1.10 Corda的Contract和以太坊中的智能合约有什么区别？ 不同点： Corda的Contract主要是为了来做验证交易是否正确的，不可以做以太坊智能合约的转账的操作。 以太坊中的智能合约是一个特殊的账户，里面有余额、交易次数、代码、存储等；但是Corda的Contract只有代码，只用来验证交易是否正确。 相同点： 只要执行中遇到异常就表示验证不通过；能够证明交易非法（不符合合约内容）。 3、如何基于Corda构建应用 详情查看： 如何开发一个CorDapp 如何搭建一个Corda网络 4、Corda汇总 Corda优点 隐私保护做的很好，交易只有涉及到的节点才知道 提供了一些通用的State类，如现金、商品、商业票据、利率交换、债务等 开发CorDapp简单，可以直接使用Java开发并且有模板和套路可循","categories":[],"tags":[]},{"title":"blockchain/3如何开发一个CorDapp","slug":"blockchain/3如何开发一个CorDapp","date":"2020-12-11T06:19:42.000Z","updated":"2020-12-11T06:19:42.000Z","comments":true,"path":"2020/12/11/blockchain/3如何开发一个CorDapp/","link":"","permalink":"https://nijixucai.github.io/2020/12/11/blockchain/3%E5%A6%82%E4%BD%95%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AACorDapp/","excerpt":"","text":"环境准备 JDK（8u131以上） corda训练营 代码地址： https://github.com/corda/bootcamp-cordapp 个人gitee项目：https://gitee.com/zheshiyigegexingwangzhan/bootcamp-cordapp.git 添加国内镜像 当前项目修改 下载代码之后为了更快的下载依赖，添加国内的镜像： 1maven &#123; url &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&#39;&#125; 直接修改全局的gradle配置 在**~/.gradle目录下新建init.gradle**文件，写入以下内容： 1234567891011121314151617181920212223allprojects&#123; repositories &#123; def ALIYUN_REPOSITORY_URL &#x3D; &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#39; def ALIYUN_JCENTER_URL &#x3D; &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;jcenter&#39; all &#123; ArtifactRepository repo -&gt; if(repo instanceof MavenArtifactRepository)&#123; def url &#x3D; repo.url.toString() if (url.startsWith(&#39;https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#39;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_REPOSITORY_URL.&quot; remove repo &#125; if (url.startsWith(&#39;https:&#x2F;&#x2F;jcenter.bintray.com&#x2F;&#39;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_JCENTER_URL.&quot; remove repo &#125; &#125; &#125; maven &#123; url ALIYUN_REPOSITORY_URL url ALIYUN_JCENTER_URL &#125; &#125;&#125; 测试代码 运行ProjectImportedOKTest单测，如果通过说明环境没有问题 我的运行结果如下： 123456789&gt; Configure project :Repository https:&#x2F;&#x2F;jcenter.bintray.com&#x2F; replaced by http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;jcenter.&gt; Task :compileJava&gt; Task :processResources NO-SOURCE&gt; Task :classes&gt; Task :compileTestJava&gt; Task :processTestResources NO-SOURCE&gt; Task :testClasses&gt; Task :test 代码开发 State开发 一个state需要实现ContractState，ContractState中有一个方法getParticipants()，返回的是List&lt;AbstractParty&gt;,表示在这个state发生了交易时需要通知谁，让谁知道。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package bootcamp;import com.google.common.collect.ImmutableList;import net.corda.core.contracts.ContractState;import net.corda.core.identity.AbstractParty;import net.corda.core.identity.Party;import org.jetbrains.annotations.NotNull;import java.util.List;public class IouState implements ContractState &#123; /** * 发行人 */ private Party issuer; /** * 拥有者 */ private Party owner; /** * 金额 */ private int amount; public IouState(Party issuer, Party owner, int amount) &#123; this.issuer = issuer; this.owner = owner; this.amount = amount; &#125; @NotNull @Override public List&lt;AbstractParty&gt; getParticipants() &#123; return ImmutableList.of(issuer, owner); &#125; public Party getIssuer() &#123; return issuer; &#125; public Party getOwner() &#123; return owner; &#125; public int getAmount() &#123; return amount; &#125;&#125; Contract开发 一个contract简单的理解就是一些校验的规则，需要实现Contract类，Contract类如下，只有一个verify方法，验证LedgerTransaction是否正确，如果不正确就抛IllegalArgumentException异常。 12345678910interface Contract &#123; /** * Takes an object that represents a state transition, and ensures the inputs/outputs/commands make sense. * Must throw an exception if there's a problem that should prevent state transition. Takes a single object * rather than an argument so that additional data can be added without breaking binary compatibility with * existing contract code. */ @Throws(IllegalArgumentException::class) fun verify(tx: LedgerTransaction)&#125; 在开发一个contract时，Corda提议的三个验证的类型： 输入与输出个数的校验（Shape Constraint，No. input states, No. output states, command） 输入与输出的内容的校验（Context Constraint），业务校验 需要的签名的校验（Required Singer Constraint） 按照上图的规则IouContract的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package bootcamp;import net.corda.core.contracts.Command;import net.corda.core.contracts.CommandData;import net.corda.core.contracts.Contract;import net.corda.core.contracts.ContractState;import net.corda.core.transactions.LedgerTransaction;import org.apache.commons.collections4.CollectionUtils;public class IouContract implements Contract &#123; public static String ID = \"bootcamp.IouContract\"; @Override public void verify(LedgerTransaction tx) &#123; // 1、Shape Constraint，No. input states, No. output states, command if (tx.getCommands().size() != 1) &#123; throw new IllegalArgumentException(\"command size must be one\"); &#125; Command&lt;CommandData&gt; command = tx.getCommand(0); if (!(command.getValue() instanceof Commands.Issue)) &#123; throw new IllegalArgumentException(\"command must be Issue\"); &#125; if (CollectionUtils.isNotEmpty(tx.getInputs())) &#123; throw new IllegalArgumentException(\"Issue must be not inputs\"); &#125; if (tx.getOutputs().size() != 1) &#123; throw new IllegalArgumentException(\"Issue outputs must be one\"); &#125; ContractState output = tx.getOutput(0); // 2、Context Constraint if (!(output instanceof IouState)) &#123; throw new IllegalArgumentException(\"state must be IouState\"); &#125; IouState iouState = (IouState) output; if (iouState.getAmount() &lt;= 0) &#123; throw new IllegalArgumentException(\"issue amount must big than zero\"); &#125; // 3、Required Singer Constraint if (!command.getSigners().contains(iouState.getIssuer().getOwningKey())) &#123; throw new IllegalArgumentException(\"issue business must be sing by issuer\"); &#125; &#125; public interface Commands extends CommandData &#123; class Issue implements Commands &#123; &#125; &#125;&#125; Flow开发 flow有两种 可以在本地主动启动的flow 只能通过其他的flow启动的flow 发起一个交易的flow都是可以在本地主动启动的flow，有以下特点 需要添加注解@InitiatingFlow来表示他是一个可以初始化的flow 需要添加注@StartableByRPC或者@StartableByService来说明启动的方式 flow需要继承自FlowLogic，业务逻辑在call方法中实现 call方法需要添加@Suspendable注解 指定notary，校验是否双花 创建交易，交易中必须包含command，如果有output必须指定contract来进行验证；可以没有input 然后就是通用的流程，验证交易、收集签名、交易入库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package bootcamp;import co.paralleluniverse.fibers.Suspendable;import com.google.common.collect.ImmutableList;import net.corda.core.contracts.StateAndRef;import net.corda.core.flows.*;import net.corda.core.identity.Party;import net.corda.core.transactions.SignedTransaction;import net.corda.core.transactions.TransactionBuilder;import net.corda.core.utilities.ProgressTracker;import static java.util.Collections.singletonList;/** * * @author nicai */@InitiatingFlow@StartableByRPCpublic class IouIssueFlowInitiator extends FlowLogic&lt;SignedTransaction&gt; &#123; private final Party owner; private final int amount; public IouIssueFlowInitiator(Party owner, int amount) &#123; this.owner = owner; this.amount = amount; &#125; private final ProgressTracker progressTracker = new ProgressTracker(); @Override public ProgressTracker getProgressTracker() &#123; return progressTracker; &#125; @Suspendable @Override public SignedTransaction call() throws FlowException &#123; // We choose our transaction's notary (the notary prevents double-spends). Party notary = getServiceHub().getNetworkMapCache().getNotaryIdentities().get(0); // We get a reference to our own identity. Party issuer = getOurIdentity(); // We create our new IouState. IouState iouState = new IouState(issuer, owner, amount); // We build our transaction. TransactionBuilder transactionBuilder = new TransactionBuilder(notary)// .addInputState() .addOutputState(iouState, IouContract.ID) .addCommand(new IouContract.Commands.Issue(), ImmutableList.of(issuer.getOwningKey(), owner.getOwningKey())); // We check our transaction is valid based on its contracts. transactionBuilder.verify(getServiceHub()); FlowSession session = initiateFlow(owner); // We sign the transaction with our private key, making it immutable. SignedTransaction signedTransaction = getServiceHub().signInitialTransaction(transactionBuilder); // The counterparty signs the transaction SignedTransaction fullySignedTransaction = subFlow(new CollectSignaturesFlow(signedTransaction, singletonList(session))); // We get the transaction notarised and recorded automatically by the platform. return subFlow(new FinalityFlow(fullySignedTransaction, singletonList(session))); &#125;&#125; 被动启动的flow有以下特点： 需要注解@InitiatedBy(IouIssueFlowInitiator.class)指定谁能启动这个flow flow需要继承自FlowLogic，业务逻辑在call方法中实现 call方法需要添加@Suspendable注解 需要有实例变量FlowSession，保存调用者的FlowSession call方法需要验证交易，然后执行接收交易的标准流程ReceiveFinalityFlow 1234567891011121314151617181920212223242526272829package bootcamp;import co.paralleluniverse.fibers.Suspendable;import net.corda.core.flows.*;import net.corda.core.transactions.SignedTransaction;@InitiatedBy(IouIssueFlowInitiator.class)public class IouIssueFlowResponder extends FlowLogic&lt;Void&gt; &#123; private final FlowSession otherSide; public IouIssueFlowResponder(FlowSession otherSide) &#123; this.otherSide = otherSide; &#125; @Override @Suspendable public Void call() throws FlowException &#123; SignedTransaction signedTransaction = subFlow(new SignTransactionFlow(otherSide) &#123; @Suspendable @Override protected void checkTransaction(SignedTransaction stx) throws FlowException &#123; // Implement responder flow transaction checks here &#125; &#125;); subFlow(new ReceiveFinalityFlow(otherSide, signedTransaction.getId())); return null; &#125;&#125; 运行 打包 1./gradlew deployNodes 运行所有的节点 1sudo ./build/nodes/runnodes 启动一个流程 1flow start IouIssueFlow owner: PartyB, amount: 99 我本地日志如下： 1234567 ✅ Starting Requesting signature by notary service Requesting signature by Notary service Validating response from Notary service ✅ Broadcasting transaction to participants➡️ DoneFlow completed with result: SignedTransaction(id=14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0) 查询生成的数据 1run vaultQuery contractStateType: bootcamp.IouState 我本地的结果如下 1234567891011121314151617181920212223242526272829303132states:- state: data: !&lt;bootcamp.IouState&gt; issuer: \"O=PartyA, L=London, C=GB\" owner: \"O=PartyB, L=New York, C=US\" amount: 99 contract: \"bootcamp.IouContract\" notary: \"O=Notary, L=London, C=GB\" encumbrance: null constraint: !&lt;net.corda.core.contracts.SignatureAttachmentConstraint&gt; key: \"aSq9DsNNvGhYxYyqA9wd2eduEAZ5AXWgJTbTEw3G5d2maAq8vtLE4kZHgCs5jcB1N31cx1hpsLeqG2ngSysVHqcXhbNts6SkRWDaV7xNcr6MtcbufGUchxredBb6\" ref: txhash: \"14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0\" index: 0statesMetadata:- ref: txhash: \"14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0\" index: 0 contractStateClassName: \"bootcamp.IouState\" recordedTime: \"2020-12-03T09:49:48.373Z\" consumedTime: null status: \"UNCONSUMED\" notary: \"O=Notary, L=London, C=GB\" lockId: null lockUpdateTime: null relevancyStatus: \"RELEVANT\" constraintInfo: constraint: key: \"aSq9DsNNvGhYxYyqA9wd2eduEAZ5AXWgJTbTEw3G5d2maAq8vtLE4kZHgCs5jcB1N31cx1hpsLeqG2ngSysVHqcXhbNts6SkRWDaV7xNcr6MtcbufGUchxredBb6\"totalStatesAvailable: -1stateTypes: \"UNCONSUMED\"otherResults: [] 节点可视化工具 参考网站：https://docs.corda.net/docs/corda-os/4.6/node-explorer.html 可以下载node-explorer来查看节点信息。 第一次打开界面 Node Hostname：localhost Node Port：RPC connection address可以在启动的窗口查看，或者配置文件查看 RPC Username：在配置文件 RPC Password:在配置文件查看 使用spring开发corda： https://manosbatsis.github.io/corbeans/","categories":[],"tags":[]},{"title":"blockchain/4如何搭建一个Corda网络","slug":"blockchain/4如何搭建一个Corda网络","date":"2020-12-11T06:13:43.000Z","updated":"2020-12-11T06:13:43.000Z","comments":true,"path":"2020/12/11/blockchain/4如何搭建一个Corda网络/","link":"","permalink":"https://nijixucai.github.io/2020/12/11/blockchain/4%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AACorda%E7%BD%91%E7%BB%9C/","excerpt":"","text":"在查看此文档之前，先查看如何开发一个CorDapp 参考文档：NMS的FAQ.md文件 1、网络服务启动，docker版的网络服务启动： 1docker run --name=network-map -e NMS_ROOT_CA_FILE_PATH=\"\" -p 8080:8080 cordite/network-map:latest 2、启动后打开接口文档用于验证启动是否成功 http://localhost:8080/swagger/#/ 3、build和配置CorDapp build之前修改build.gradle的配置，修改cordapp节点不给cordapp签名 123456cordapp &#123; signing &#123; enabled false &#125; // 其他配置&#125; 运行build命令 1./gradlew clean deployNodes 修改配置删除自动生成的key等文件 123456789pushd build/nodesfor N in */; do echo 'compatibilityZoneURL=\"http://localhost:8080\"' &gt;&gt; $N/node.conf echo 'devModeOptions.allowCompatibilityZone=true' &gt;&gt; $N/node.conf pushd $N rm -rf network-parameters nodeInfo-* persistence.mv.db certificates additional-node-infos popddonepopd 4、把节点注册到网络 下载网络的truststore 1curl http://localhost:8080/network-map/truststore -o ~/tmp/network-truststore.jks 每个节点都初始化注册 1234567pushd build/nodesfor N in */; do pushd $N java -jar corda.jar --initial-registration --network-root-truststore ~/tmp/network-truststore.jks --network-root-truststore-password trustpass popddonepopd 5、指定Notary节点 启动Notary节点 进到Notary节点的目录下执行,如果没有权限 1java -jar corda.jar 注意：如果报错：Unable to create logging directory /Users/apple/code/open-source/blockchain/my-corda/logs. Node will now shutdown.说明没有权限，在命令前加sudo即可 指定Notary节点 1、登陆NMS（network-map-service）并获取token信息 1TOKEN=`curl -X POST \"http://localhost:8080//admin/api/login\" -H \"accept: text/plain\" -H \"Content-Type: application/json\" -d \"&#123; \\\"user\\\": \\\"sa\\\", \\\"password\\\": \\\"admin\\\"&#125;\"` 2、上传notary 1234pushd build/nodes/NotaryNODEINFO=`ls nodeInfo*`curl -X POST -H \"Authorization: Bearer $TOKEN\" -H \"accept: text/plain\" -H \"Content-Type: application/octet-stream\" --data-binary @$NODEINFO http://localhost:8080//admin/api/notaries/validatingpopd 在执行上面的命令时，注意自己当前的所在的目录，如果已经在build/nodes/Notary目录下需要退出到bootcamp-cordapp目录 6、停止Notary节点 在notary节点的shell命令行执行 bye 7、修改notary节点的validating 因为在第5步指定Notary的时候调用的是validating接口，所以确认一下notary的配置是的validating是否为true，如下 123notary &#123; validating&#x3D;true&#125; 如果配置的是validating=false则会报异常： [ERROR] 16:25:22+0800 [main] internal.NodeStartupLogging. - Exception during node startup: There is a discrepancy in the configured notary type and the one advertised in the network parameters - shutting down. Configured as validating: false. Advertised as validating: true [errorCode=r8le54, moreInformationAt=https://errors.corda.net/OS/4.3/r8le54] 8、删除Notary节点的network-parameters文件 进入到notary节点的目录，删除network-parameters文件 9、启动notary节点和其他节点 进入到各个节点的目录，启动： 1java -jar corda.jar 10、发起交易测试 可以下载node-explorer来查看节点信息并发起交易，我的测试结果如下： 扩展 因为上面的文档是按照","categories":[],"tags":[]},{"title":"blockchain/1北京大学肖臻老师《区块链技术与应用》学习总结","slug":"blockchain/1北京大学肖臻老师《区块链技术与应用》学习总结","date":"2020-12-11T06:13:05.000Z","updated":"2020-12-11T06:13:05.000Z","comments":true,"path":"2020/12/11/blockchain/1北京大学肖臻老师《区块链技术与应用》学习总结/","link":"","permalink":"https://nijixucai.github.io/2020/12/11/blockchain/1%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E8%82%96%E8%87%BB%E8%80%81%E5%B8%88%E3%80%8A%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E3%80%8B%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"北京大学肖臻老师《区块链技术与应用》学习总结 3 数据结构 hash printers （hash指针） hash指针既可以找到块的位置，也可以验证hash的正确性 Block chain is a linked list using hash pointers 每一个区块都包含前一个区块的hash指针 后面一个区块的hash指针是通过前一个区块的值算出来的。 通过上面的数据结构可以实现：tamper-evident-log 只要记住最后一个块的hash值，就可以保证整个链的值无法篡改。 我们也可以只保存其中的部分区块，区块的前面的部分我们不必保存，如果需要的时候找别人要；然后验证要的区块的hash值是否是当前区块的hash值即可 Merkle tree 上图： 最下面的一层是数据块，data blocks；每个数据块都是交易（tx） 上面的那些都是hash pointers 最上面的节点是根hash值（root hash） Merkle tree数据结构的好处： 只要记住root hash就可以检测出节点的修改 每个区块分成块头（block header）和块身（block body） 默克尔证明（Merkle proof）：指一笔交易到跟节点的路径 这种证明也叫做：proof of membership或proof of inclusion（证明节点存在于Merkle tree之中） proof of non-membership（证明节点存不在于Merkle tree之中） 排序所有交易节点的hash值（Sorted Merkle tree），然后计算需要证明的交易的hash值，找到此hash值应该出现的位置，如果应该出现的位置的两边的节点的hash满足Merkle proof，则说明需要证明的节点不在此Merkle tree之中。 只要不是有环的数据结构，都可以使用hash指针 4 BTC 协议 如何发行数字货币 央行发行数字货币，如果只使用私钥签名，可以吗？ 无法防止double spending attack：花两次攻击 中心化方案： 如果央行给发行的货币打上编号并且记录货币当前属于谁，那么可以解决double spending attack； 但是每次花钱都要去央行验证货币是否是真的，并且属于当前花钱的人，花钱之后再变更钱的归属。 去中心化方案 每个交易（如A给B转账）中都包含输入和输出两个部分 输入部分需要说明币的来源 输入部分需要包含付款人的公钥（因为付款时有付款人的签名，带上公钥为了供别人校验） 输出部分要给出收款人公钥的hash 铸币交易（coinbase tx）里面有A的公钥的hash，这样就知道铸币交易的钱是给谁的。 上图中的数据结构有两种hash指针 第一种是链接块的hash指针（即前一个区块的hash指针） 第二种hash指针是说明币的来源 问题：是否可以检测dobule spending？ 如果币的来源是不合法的（验证不合法的方式是币的来源是否存在与UTXO），是不会添加到区块链中，可以检测dobule spending 问题：在A给B转账时，所有人都需要知道A的公钥，为了验证A的签名；那么怎么才能知道A的公钥呢？ 在交易的输入部分，付款人需要给出自己的公钥 在比特币的系统里，地址是通过公钥推算出来的，地址相当于银行账号，A需要给B转钱需要B的地址；比特币系统里面是没有功能查询某个人的地址 BitCoin Script：交易脚本，把A的输入部分和上一步的输出脚本拼在一起执行，如果不报错说明交易是合法的。 每一个块包含不止一个交易，每个块包含Block header和Block body 哈希指针包含的hash，是通过Block header做hash的值 Block header包含： version：用的哪个比特币协议的版本 hash of previous block header：上一个区块头的hash Merkle root hash：整个Tree的root hash值 target：挖矿的目标target（满足H(block header + nonce) &lt;= target） 随机数nonce Block body包含： transaction list 系统中的节点分为全节点和轻节点 full node 全节点是保存区块链的所有信息的，验证每一个交易，所以全节点也叫做fully validating node light node 轻节点无法独立验证交易的合法性 问题：每个账户都可以发布交易，谁来决定哪个交易写到区块中？顺序是什么样的？ 挖矿决定谁有记账权，有记账权的节点可以申请写入区块，顺序由拥有记账权的节点定 账本的内容要取得分布式的共识 distributed consensus（分布式共识） distributed hash table 需要取得共识的内容是什么？ FLP impossibility result： 在一个异步的系统里，即使只有一个成员是有问题的，也不可能取得共识 CAP Theorem（定理） CAP： 一致性 （Consistency） 可用性 （Availability） 分区容错性 （Partition tolerance） 这三个特性分布式系统中最多同时满足两个 分布式的一个协议：Paxos，能够保证Consistency 比特币中的共识协议Consensus in BitCoin 假设系统中大部分的节点是好的，小部分有恶意。 直接投票选择哪些交易是合法的，如果超过半数就接受可以吗？ membership，谁有投票权 hyperledger fabric（联盟链）：可以投票决定 sybil attack（女巫攻击）：超级计算机一直制造账户，参与投票，直到制造的恶意账户超过半数。 比特币的投票，按照算力值 谁先获得下面公式中的nonce，谁就能获得记账权，并且给予初块奖励 Puzzle friendly: H(block header) &lt;= target longest valid chain 最长合法链 如果不在最长合法链上，新的区块也不会被接受； 上面的图片是分叉攻击（forking attack） block reward 初块奖励 一次性能造多少币？ 刚发布的时候50 BTC，21万个区块之后可以铸造25个比特币 50 BTC -&gt; 25 BTC -&gt; 12.5 BTC coinbase transaction mining（挖矿）：争夺记账权 digital gold：数字黄金 miner：矿工 BTC 实现 transaction-based ledger：基于交易的账本模式 每个区块记录的是交易信息，包括转账交易和铸币交易 UTXO：Unspent Transaction Output（还没有被花出去的输出） UTXO数据结构，以便快速检测double spending；如果想花掉的币不存在UTXO中，说明不存在或已经花出 total inputs = total outputs 比特币的第二个激励机制：transaction fee 其他的模式：account-based ledger，在这种模式中，系统要显示的记录账户的余额，以太坊是基于此种模式记账。 每次尝试nonce可以看作是Bernoulli trial：a random experiment with binary outcome 所有的尝试的集合构成了Bernoulli Process：a sequence of independent Bernoulli trials 尝试计算nonce是memoryless的：即无论以前尝试过多少次下一次的概率还是一样 可以使用Poisson Process近似 出块时间服从指数分布：exponential distribution BitCoin is secured by mining 比特币的安全性 问题：能不能把别人的钱转给自己？ 不可以，因为你没有别人的私钥，无法签名。（比特币在花每一笔钱的时候都要制定币的来源，即某次交易的output，这个output中有币的所有人的公钥，在花钱的时候币的所有人需要用自己的私钥做签名，然后别人通过当前交易的input和币来源的output来验证这个交易的合法性。） 问题：能不能double spending？ 不可以，因为第二次花的时候在UTXO里面不存在，会验证不通过。 6-BTC-网络 application layer：BitCoin Block chain network layer：P2P Overlay Network 设计原则：simple, robust, but not efficient 7-BTC-挖矿难度 如何调整挖矿难度：调整挖矿难度就是调整目标空间在整个输出空间中所占的比例。 挖矿即是算出满足：H(block header) &lt;= target的nonce值 sha-256: 可能的值是2的256次方 difficulty = difficulty_1_target/target 问题：为什么要调整挖矿难度？ 为了保证出块时间平均10分钟 问题：出块时间太短会有什么问题？ 两个节点同时发布区块，可能会出现分叉 平均出块时间过短可能导致上图的很多分叉，这会分散诚实节点的算力 平均出块时间不论设置的多长，都不可以无限的减小下去 如果分叉过多就无法防止51% attack 以太坊的共识协议：ghost 什么时候调整难度？ 每2016个区块之后调整一次 如何调整挖矿难度： 调整的target值 **公式：**target = target_current * (actual time)/(expected time) 当actual time大于expected time，说明难度太大， (actual time)/(expected time)得出的值就大于1，最终算出来的target会比当前的target大，也就是变得容易 调整难度 next_difficulty = previous_diffculty * (2 weeks)/ (time to mine last 2016 blocks) 调整难度与目标域值（target）成反比 expected time = 2016 * 10min actual time = time spent mining the last 2016 blocks 目标域值调整最大不会超过4倍，最小不会小于1/4 怎么让所有的矿工都调整域值呢？ 代码里自动调，如果恶意节点修改了源码不调整，他发布的区块的检查区块合法性就通不过。 8-BTC-挖矿 全节点 一直在线 在本地硬盘上维护完整的区块链信息 在内存里维护UTXO，以便快速验证交易的正确性 监听比特币网络上的交易信息，验证每个交易的合法性 决定哪些交易会被打包到区块里 监听别的矿工挖出来的区块，验证其合法性 挖矿 决定沿着哪条链挖下去？ 当出现等长的分叉的时候，选择哪个分叉？ 缺省情况下是沿着最先听到的区块 轻节点 不是一直在线 不用保存整个区块链，只要保存每个区块的块头 不用保存全部交易，只保存与自己相关的交易 无法检验大多数交易的合法性，只能检测与自己相关的那些交易的合法性 无法检测网上发布的区块的正确性 可以验证挖矿的难度 只能检测哪个是最长链，不知道哪个是最长合法链 挖矿具有特性： memoryless或叫做progress free 挖矿的设备 第一代，CPU 闲置的cpu、内存、硬盘 第二代，GPU 为了通用并行计算而设计的 也存在浪费 第三代，ASIC：Application Specific Integrated Circuit 挖矿的设备的趋势是从通用到专业 puzzle mining puzzle:挖矿时求解的puzzle merge mining：使用别的币的mining puzzle Alternative mining puzzle: 抗ASIC芯片 矿池 （share almost valid block） 假如一个矿池占了51%的比例，他能发动哪些攻击呢？ forking attack Boycott（封锁） 9-BTC-比特币脚本 比特币脚本是stack-based的脚本，包括下面三种类型 P2PK（Pay to Public Key） P2PH（Pay to Public Key Hash） P2SH（Pay to Script Hash）对多重签名的支持 redeemScript： 当一个需要联合签名的账号B（如需要5个中的三个签名）需要支付时，需要至少有三个签名才可以，那么在B支付给C时需要验证B的币来来源的output和当前的交易的input做验证。如果需要验证成功则需要在上一步交易的output中包含这些公钥信息。 当一个账号A支付给另一个需要联合签名的账号B时，如果需要A支付时提供B的所有的账户的公钥信息，会导致A支付时特别麻烦。 redeemScript就是解决上面的问题而存在的，详情参考深入理解比特币脚本 Proof of Burn 燃烧证明，在输出脚本中添加return，使这个output在验证时永远报错，也就是这个输出的币永远也花不出去。 自问：如果A在给B付款时，output中面包含return语句，那么B虽然真实收到了款，但是永远花不出去。B能够在接收时验证吗？还是只能等到花钱时才能发现这个问题呢？ **自答：**因为B需要验证这比交易有没有写入区块链中，所以A会把交易发给B，此时B需要检查output是否包含return，如果包含则认为这比交易无效；假如B是商家并在交易刚发生时不验证，把货发送给A，那么B就收到一笔花不出去的钱。 digital commitment 发布交易不需要记账权，发布区块才需要记账权 10-BTC-分叉 fork state fork forking attack（deliberate fork） protocol fork（协议分叉） hard fork soft fork hard fork 系统中只有有一部分节点不更新软件，就会出现永久性的分叉 eg：block size limit block size不超过1M，计算出7tx/sec（每秒7笔交易）；如果new nodes把软件升级为区块大小最多可以4M，那么旧的节点如果不一起升级继续沿着旧链挖就会导致硬分叉；旧节点认为超过1M大小的区块为非法的。 只要old nodes不更新软件，分叉就不会变更 soft fork 只要系统中有半数中的节点更新软件，就不会出现永久性的分叉；只会出现临时性的分叉 接着使用调整区块大小的例子，如果调整为限制不超过0.5M，那么新节点产生的区块旧节点也认可；但是旧节点产生的区块新节点不认可，如果新节点占多数时就会迫使旧节点升级。 软分叉的例子（P2SH：Pay to Script Hash） 11-BTC-问答 如果转账的时候地址写错了怎么办？ 答：没有办法取消一经发布的交易 Proof of Burn，如果OP_RETURN无条件的返回错误，这笔交易是如何写入到区块链里的呢？ 答：因为OP_RETURN是写在当前交易的输出脚本里，所以当前交易的验证不会验证这个脚本 你怎么知道哪个矿工最先找到的同一个nonce？ 答：不可以偷答案，因为区块里面的coinbase tx指向的收款账户是真正计算出nonce的账户，这个信息如果被修改了，交易就不会验证通过。 transaction fee，如何确定交易费给哪个矿工，给多少？ 只要total inputs &gt; total outputs，之间的差额就是交易费 12-BTC-比特币中的匿名性 BitCoin and anonymity pseudonymity 什么情况下会破坏匿名性？ 在多个inputs的时候，多个输入可能是同一个人 什么情况下别人能直到比特币账户对应现实中的某个人呢？ 资金的转入转出，购买比特币或者比特币套现；比特币支付的时候也可以 silk road：eBay for illegal drugs 采取什么方法提高匿名性？ 零知识证明 零知识证明是指一方（证明者）向另一方（验证着）证明一个陈述是正确的，而无需透露除该陈述是正确的外的任何信息。 **我的理解：**如比特币的转账（A转给B）签名就是零知识证明，因为这个签名证明了这个交易是A转出去的，却不需要让A提供其他信息。 13-BTC-思考 为什么比特币系统能够绕过被证明的分布式系统的不可能的结论？ 比特币并没有绕过 14-ETH-以太坊概述 memory hard mining puzzle ASIC resistance：挖矿时需要访问内存 proof of work -&gt; proof of stake：目标是从工作量证明过度到权益证明 smart contract: 智能合约 BitCoin: decentralized currency（去中心化的货币） Ethereum: decentralized contract（去中心化的合同） 15-ETH-账户 以太坊是一个accounting-based ledger（基于账户的去中心化的账本） 天然防御double spending attack 记录交易次数（nonce），以防御replay attack（重放攻击） 账户类型 externally owned account（外部账户） 记录： balance nonce Smart contract account（智能合约账户） 记录： balance nonce code storage 智能合约账户有以下几个特点： 合约账户无法主动发起一个交易 创建合约账户的时候会返回一个地址，可以调用这个地址 16-ETH-以太坊中的状态树 维护的功能是账户地址到账户状态的映射：addr -&gt; state 问题：如果把所有账户直接组成一个merkle tree 可以吗？ 不可以，因为修改账户时成了串行 问题：为什么比特币可以把所有交易组成一个merkle tree呢？ 因为比特币只有一个人拥有记账权，所以这个有记账权的人随意记录即可 即使以太坊使用sorted merkle tree，在有新的账户出现时也会大量的更新merkle tree中的hash值。 数据结构：trie（retrieval-检索） 数据结构：Patricia tree（trie） 树的高度变短 如果插入新的单词，原来压缩的节点可能需要扩展开 数据结构：MPT（Merkle Patricia tree） 把Patricia tree的指针改为Hash Pointer就成了MPT 数据结构：Modified MPT 下面状态树的例子中的节点有三种： Extention Node：如果路径出现压缩，就会出现此节点 Branch Node：分支节点 Leaf Node：最终的节点 16-ETH-交易树和收据树 用处： 提供Merkle proof 数据结构：bloom filter **用途：**支持查找某个元素是否在一个比较大的集合中 **实现：**把集合中的所有的hash值映射到一个小的数组中，然后把数组中的对应位置的值由0改为1。 有可能出现误报（一个值的hash映射的数组中的位置，如果是1只能说明可能存在，因为存在hash碰撞） 不会出现漏报（因为只要某个值的hash映射的数组的位置的值是0，说明此值不存在） 以太坊中如何使用bloom filter 包含在块头里面，可以快速过滤某些节点不包含指定交易；然后再在可能包含的节点中检索。 transaction-driven state machine（交易驱动的状态机） 18-ETH-GHOST协议 如果只有和父节点平级的才是uncle block 存在问题： 1、uncle block的个数只能是两个，如果分叉超过3个就无法全部包含进来。 2、故意不包含某个叔父区块 只要与当前节点有共同的主链就认为是uncle block 存在问题： 某个矿工在挖矿难度低的时候产生多个分叉（即以后节点的叔父）区块，期待以后被包含进去以获取初块奖励 GHOST协议：与当前区块在7代以内，才被认为是uncle block 距离当前区块越远的uncle block，得到的奖励越少；为了防止分叉过多，有利于鼓励出现分叉尽快合并。叔父区块得不到gas fee（汽油费） 19-ETH-挖矿算法（ethash） Block chain is secured by mining。 bug bounty：bug赏金 one cpu， one vote（一个cpu，一张投票） 设计puzzle的原则：difficult to solve， but easy to verify 以太坊的挖矿算法的目标是做到：AISC resistance memory hard mining puzzle 20-ETH-难度调整 自适应难度调整 子公式解释 难度炸弹（difficulty bomb） 以太坊发展的四个阶段 21-权益证明（Proof of stake） TWH：Terawatt hours 问题：为什么需要权益证明？ 工作量证明太费电了 初块奖励是为了激励矿工参与比特币系统的维护。 virtual mining 权益证明： 每个人按照持有币的数量来投票，省去了挖矿的过程；持有的币越多，权益越大。 持有的币只能从加密货币的系统中获取，如果有人大量购买这个币以获取权益然后搞垮他，会导致币价大涨；涨价会让搞垮这个币所付出的代价很大。 AltCoin Infanticide：把新币扼杀在摇篮里 Proof of Deposit 如果出现分叉的时候，一个人两边都挖，并不会影响他的币的数量。 Casper the Friendly Finality Gadget（FFG） 验证者有任期，验证者在任期外有等待期，如果没有人检举则给验证者保证金和奖励。 EOS币的权益证明： DPOS：Delegated Proof of Stake 22-ETH-智能合约 外部账户如何调用智能合约？ SENDER ADDRESS：调用者的地址 TO CONTRACT ADDRESS：智能合约的地址 VALUE：调用时转多少ETH GAS USED：汽油费 GAS PRICE：汽油费的价格 CAS LIMIT：此调用愿意支付的汽油费上限 TX DATA：调用的函数及其参数的编码值 一个合约如何调用另一个合约中的函数 1、直接调用 2、使用adress类型的call()函数 3、代理调用delegatecall() 错误处理 assert：一般用来判断内部条件 required：一般用于判断外部条件 revert：无条件的抛出异常 嵌套调用 先执行交易再挖矿,因为挖矿之后发布的账户状态需要先执行交易。 就算账户的代码执行错误，也会被发布；然后收取汽油费，为了防止有恶意节点发送大量的不能验证通过的交易。 问题：智能合约的代码支持多线程执行吗？ 不支持多线程,多线程可能造成执行结果的不一致。 智能合约可以获得的区块信息 智能合约可以获得的调用信息 地址类型 地址类型中的不同方法转账时的特点： transfer：会导致连锁性回滚 send：不会导致连锁性回滚 call：不会导致连锁式回滚，call的方式转账会把剩余的汽油全部发送过去 一个例子：简单拍卖 构造方法 出价和结束拍卖的方法 如果黑客的智能合约中没有callback方法怎么办？ 没有办法。。。 Code is low： 优点：没有人能够修改规则 缺点：如果规则有问题，也无法修正，导致上面的问题成为所有人的钱都取不出来 优化后的拍卖代码 无法防止重入攻击（Re-entrancy Attack） 解决的方法是，先把金额修改为0，再发起转账。 转账交易时需要使用这个步骤：先判断条件，再改变条件，再发生交互 better safe by sorry 不要使用call方法转账，因为call支付的汽油费太多 23-ETH-TheDAO DAO：Decentralized Autonomous Organization（去中心化的自治的组织） DAC：Decentralized Autonomous Corporation（去中心化的自治的公司） 因为先转账再更改余额导致被发起了重入攻击： too big to fail 升级后产生两个分叉：通过在链上增加ChainID（为了防止回放），以区分ETC(Ethereum Classic)和ETH 为什么不能只针对黑客的账户？ 因为智能合约有bug，所以就算只针对黑客的账户其他人也可以针对这个bug进行攻击。 24-ETH-思考 Is smart contract really smart？（智能合约真的智能吗） smart contract is anything but smart Nothing is irrevocable（没有什么是不可篡改的） 如TheDAO的例子；所以不能迷信“不可篡改” Is solidity the right programming language？ solidity存在一些问题，但是没有什么东西是没有问题的。所以随着时间的检验可能会出现 智能合约模板 编写智能合约的公司 虽然智能合约的内容是开源的，但是Many eyeball fallacy；在涉及到自己的利益时还是需要自己检查代码。 What does decentralization（权利下放） mean？ 分叉是去中心化和民主的体现 decentralized != distributed(去中心化不等于分布式) state machine的应用场景： mission critical application（关键任务应用程序） air traffic control（空中交通管制） stock exchange（证券交易） space shuttle（航天飞机） 智能合约是用来编写控制程序的，只有在互不信任的实体之间建立共识的操作才需要写在智能合约里 25-ETH-Beauty Chain（美链） IPO：Initial Public Offering ICO：Initial Coin Offering 美链背景介绍 下图中出现的ERC为Ethereum Request for Comments（以太坊征求意见） 因为下面的代码在计算时出现了溢出，从而导致被攻击，凭空出现了很多的代币BEC 如何预防此类（计算溢出）问题？ 26-总结 加密货币应该用在法币支持的不太好的地方，而不是用在法币已经支持的很好的地方。 下一代的的互联网是价值交换网络 Democracy is the worst from of Government except for all those other forms that have bean tried from time to time Is decentralized aways right thing?","categories":[],"tags":[]},{"title":"others/读书笔记-《我的第一本算法书》","slug":"others/读书笔记-《我的第一本算法书》","date":"2020-09-30T03:23:49.091Z","updated":"2020-09-30T03:25:26.358Z","comments":true,"path":"2020/09/30/others/读书笔记-《我的第一本算法书》/","link":"","permalink":"https://nijixucai.github.io/2020/09/30/others/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E7%AE%97%E6%B3%95%E4%B9%A6%E3%80%8B/","excerpt":"","text":"第一章：数据结构 链表 特性 呈线性排列的数据结构，元素中有字段指向下一个元素 内存 内存空间不连续 时间复杂度 删除： 直接在最后把指向被删除的元素改为指向被删除的下一个元素修改即可 时间复杂度：O(1) 添加： 直接在当前列表的最后的元素的指向另一个元素即可 时间复杂度：O(1) 查询： 需要从最开始的元素查询 时间复杂度：O(n) 扩展 循环链表，最后一个元素的下一个元素指向开头的元素 每个元素有两个指向，分别指向前一个元素和后一个元素 数组 特性 呈线性排列的数据结构，元素有下标 内存 元素在内存中是连续的 时间复杂度 添加： 首先需要在末尾增加需要的存储空间，把需要添加的位置以及以后的元素的下标全部+1，把需要添加的位置放进新的元素 时间复杂度：O(n) 删除： 依此把需要删除的位置的以后的元素的下标-1 时间复杂度：O(n) 查询： 根据下标直接随机访问 时间复杂度：O(1) 栈 特性 呈线性排列的数据结构；后进先出Last In First Out，简称 LIFO push（入栈），pop（出栈） 时间复杂度 入栈和出栈，时间复杂度都是：O(1) 队列 特性 呈线性排列的数据结构；先进先出First In First Out，简称FIFO 入队，出队 时间复杂度 入队和出队的时间复杂度都是：O(1) 哈希表 特性 哈希表存储的是由键（key）和值（value）组 成的数据 如果在hash值不冲突时，哈希表的每个桶都只保存一个key；如果hash值冲突了，则会变成链表存储 先用key计算hash值，将得到的哈希值除以数组的长度，求得其余数、就找到了存储位置。这样的求余运算叫作“mod 运算” 如果两个key的hash值求余后找到的存储位置已经有值，这种存储位置重复了的情况便叫作“冲突”。遇到这种情况，可使用链表在已有数据的后面 继续存储新的数据 时间复杂度 哈希表的时间复杂度与hash算法有关 如果hash值不会冲突（理想情况），则新增、修改、删除、查询的时间复杂度都是：O(1) 如果hash值全部一致，则hash表其实就是一个链表，时间复杂度也与链表一致 补充说明 在存储数据的过程中，如果发生冲突，可以利用链表在已有数据的后面插入新数据 来解决冲突；这种方法被称为“链地址法”。 除了链地址法以外，还有几种解决冲突的方法。 其中，应用较为广泛的是“开放地址法”。这种方法是指当冲突发生时，立刻计算出一个候补地址（数组上的位置）并将数 据存进去。如果仍然有冲突，便继续计算下一个候补地址，直到有空地址为止。可以通过多次使用哈希函数或“线性探测法”等方法计算候补地址。 堆 特性 堆是一种图的树形结构，被用于实现“优先队列”（priority queues）。 优先队列是一种数据结构，可以自由添加数据，但取出数据时要从最小值开始按顺 序取出。 在堆的树形结构中，各个顶点被称为“结点”（node），数据就存储在这些结点中。 堆中的节点最多有两个子节点，节点的排序为从上到下，同一行则从左到右。 堆中存储数据的规则：子节点必须大于父节点 时间复杂度 添加数据 增加节点时在最下面一行的最左边增加，如果最下面的一行没有位置则增加新的一行 如果增加的数据比父节点的数字小，则与父节点交换位置，重复此步骤直到比父节点大或者没有父节点为止 时间复杂度：O(logn) 取出数据 取出数据永远是取最上面节点的数据 最上面节点的数据被取走之后，需要重新调整 重新调整时，需要把最后的数据（即最下面一行最右边的节点）移动到最上面 然后与最上面的两个子节点做比较，如果数字小于两个子节点，则调整完成 如果最上面的数据大于子节点的数据，则与较小的子节点的位置进行交换，重复此操作直到所有父节点小于子节点为止 时间复杂度:O(logn) 二叉查找树 特性 二叉查找树（又叫作二叉搜索树或二叉排序树）是一种采用了图的树形结构的数据结构 每个节点最多有两个子节点 每个节点的值大于其左子树的任意节点的值 每个节点的值小于其右子树的任意节点的值 根据上面的特性，我们可以知道如果想要查找最小值，则在左边的最末端 时间复杂度 添加数据 从顶端开始查找添加位置 如果添加的值大于顶端的值，则往右移；小于它则往左移 时间复杂度：O(logn) 删除数据 如果删除的节点没有子节点，则直接删除此节点 如果删除的节点有一个子节点，则删除此节点后把子节点移到当前的节点 如果删除的节点有两个子节点，则删除此节点后把左边子节点的最右端移到当前节点（也可以把右边子节点的最左端移到当前节点） 上面的一句可以理解为：把小于被删除的节点的最大值移到删除的节点；或者把大于被删除节点的最小值移到删除节点 如果移动的节点还有子节点，也按照同样的方式移动 时间复杂度：O(logn) 查找数据 从顶端开始查找 如果大于查找节点的值，则向右移；如果小于查找节点的值，则向左移；循环此操作 时间复杂度：O(logn) 扩展 关于时间复杂度 如果数的形状比较均衡，查找的时间复杂度是O(logn) 如果不均衡极端情况下是一个链表，查找的时间复杂度是O(n) 以二叉查找树为基础扩展的数据结构 “平衡二叉查找树”：这种数据结构可以修正形状不均衡的树，让其始终保持均衡形态，以提高查找效率 “B 树”：二叉查找树中一个结点最多有两个子结点，如果我们把子结点数扩展为 m（m 为预先设定好的常数）。像这种子结点数可以自由设定，并且形状均衡的树便是 B 树 第二章：排序 冒泡排序 算法释义 冒泡排序就是重复“从序列右边开始比较相邻两个数字的大小，再根据结果交换两个数字 的位置”这一操作的算法。 在这个过程中，数字会像泡泡一样，慢慢从右往左“浮”到序列的 顶端，所以这个算法才被称为“冒泡排序”。 时间复杂度：O(n²) 在冒泡排序中： 第 1 轮需要比较 n -1 次 第 2 轮需要比较 n -2 次 第 n -1 轮需 要比较 1 次 因此，总的比较次数为 (n -1) +(n -2) +…+1 ≈ n² /2。这个比较次数恒定为 该数值，和输入数据的排列顺序无关。 Java代码实现 冒泡排序 选择排序 算法释义 选择排序就是重复“从待排序的数据中寻找最小值，将其与序列最左边的数字进行交换” 这一操作的算法。 在序列中寻找最小值时使用的是线性查找。 时间复杂度：O(n²) 选择排序使用了线性查找来寻找最小值，因此在 第 1 轮中需要比较 n - 1 个数字 第 2 轮需要比较 n - 2 个数字 到第 n - 1 轮的时候就只需比较 1 个数字 因此，总的比较次数与冒泡排序的相同，都是(n-1)+(n-2)+…+1 ≈ n2/2 次。 Java代码实现 选择排序 插入排序 算法释义 插入排序是一种从序列左端开始依次对数据进行排序的算法。 在排序过程中，左侧的数据陆续归位，而右侧留下的就是还未被排序的数据。 插入排序的思路就是从右侧的未排序区域内取出一个数据，然后将它插入到已排序区域内合适的位置上。 时间复杂度：O(n²) Java代码实现 插入排序 堆排序 算法释义 堆排序的特点是利用了数据结构中的堆 首先，在堆中存储所有的数据，并按降序来构建堆 然后从堆中取出数据，并把取出的数据放在最右边的空位置 时间复杂度：O(nlogn) 堆排序一开始需要将 n 个数据存进堆里，所需时间为 O(nlogn) 每轮取出最大的数据并重构堆所需要的时间为 O(logn) 由于总共有 n 轮，所以重构后排序的时间也是 O(nlogn) 因此，整体来看堆排序的时间复杂度为 O(nlogn) Java代码实现 暂无 归并排序 算法释义 归并排序算法会把序列分成长度相同的两个子序列，当无法继续往下分时(也就是每个子序列中只有一个数据时)，就对子序列进行归并。 归并指的是把两个排好序的子序列合并成一个有序序列。 该操作会一直重复执行，直到所有子序列都归并为一个整体为止。 时间复杂度:O(nlogn) 把数组拆分成不可分割的最小单元的数组，时间复杂度O(n) 依次把所有数组进行合并排序，每一轮的比较次数为O(n)；需要进行logn轮 最终的时间复杂度是O(nlogn) Java代码实现 归并排序 快速排序 算法释义 快速排序算法首先会在序列中随机选择一个基准值（pivot） 然后将除了基准值以外的数分为“比基准值小的数”和“比基准值大的数”这两个类别，再将其排列成以下形式。 [ 比基准值小的数 ] 基准值 [ 比基准值大的数 ] 接着，对两个“[ ]”中的数据进行排序之后，整体的排序便完成了。对“[ ]”里面的数据进行排序时同样也会使用快速排序。 时间复杂度：O(nlogn) 每一轮比较的次数为n次，时间复杂度O(n) 需要进行logn轮的比较 最终的时间复杂度是O(nlogn) Java代码实现 快速排序 扩展 基准值约接近数组的平均值，排序的速度越快；基准值一般都使用第一个数字 第三章：数组的查找 线性查找 特性 遍历整个数组，逐个进行比较，直到找到为止 时间复杂度：O(n) Java代码实现 线性查找 二分查找 特性 只能查找已经排好序的数组 每次查找取中间位置的值与需要查找的数字比较，如果中间值大于待查找数据，则继续在中间值左边的数组进行查找；反之亦然 时间复杂度 O(logn) 每一次查找都会把待查找的范围缩小一半，直到结束为止 查找需要logn轮，每一轮比较1次；所以时间复杂度为O(logn) Java代码实现 二分查找 第四章：图的搜索 图的定义 计算机科学或离散数学中说的“图”是下面这样的： 上图中的圆圈叫作“顶点”(也叫“结点”)，连接顶点的线叫作“边”。也就是说，由顶点和连接每对顶点的边所构成的图形就是图。图可以表示各种关系 加权图 我们可以给边加上一个值，这个值叫作边的“权重”或者“权”，加了权的图被称为“加权图”。 没有权的边只能表示两个 顶点的连接状态，而有权的边就可以表示顶点之间的“连接程度”。 所谓“程度”在不同的场景意思也不一样： 地铁线路图两站之间的权是两站之间的距离 同样是地铁线路图，两站之前的权也可以是两站之间的时间 如果是高铁站线路图，两站之间的权也可以表示两站之间的乘车费 有向图 当我们想在路线图中表示该路线只能单向行驶时，就可以给边加上箭头，而这样的图就叫 作“有向图”。 和无向图一样，有向图也可以在边上添加权重，而且根据方向的不同，权重也不一样。 如下图中，如果权重表示花费时间，则B点到C点是下坡路，反过来C到B就是上坡路。 图能给我们带来哪些便利 假设图中有两个顶点 s 和 t，而我们设计出了一种算法， 可以找到“从 s 到 t 的权重之和最小”的那条路径，如： 寻找计算机网络中通信时间最短的路径 寻找路线图中耗时最短的路径 寻找路线图中最省乘车费的路径 图在代码中如何实现 图是用来表示节点与节点的关系的，所以可以使用Map来实现图 有向图，如上面图两个节点A和B、map中key为A的值有B，而key为B的值没有A，就可以表示方向 加权图，同样适用Map实现，区别是在value中既包含下一个节点的信息，又包含权重信息加权图Java实现 图的搜索 广度优先搜索 假设我们一开始位于某个顶点(即起点)，此时并不知道图的整体结构，而我们的目的是从起点开始顺着边搜索，直到到达指定顶点(即终点)。 在此过程中每走到一个顶点，就会判断一次它是否为终点。广度优先搜索会优先从离起点近的顶点开始搜索。 Java代码实现 广度优先搜索 深度优先搜索 深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。 Java代码实现 深度优先搜索 广度优先搜索和深度优先搜索对比 广度优先搜索选择的是最早成为候补的顶点，因为顶点离起点越近就越早成为候补，所以会从离起点近的地方开始按顺序搜索; 而深度优先搜索选择的则是最新成为候补的顶点，所以会一路往下，沿着新发现的路径不断深入搜索。 贝尔曼 - 福特算法 解决的问题 贝尔曼 - 福特(Bellman-Ford)算法是一种在图中求解最短路径问题的算法。 最短路径问题就是在加权图指定了起点和终点的前提下，寻找从起点到终点的路径中权重总和最小的那条路径。 求解的步骤 首先设置各个顶点的初始权重 :起点为 0，其他顶点为无穷大(∞)；这个权重的意思是从起点到当前节点的最短路径暂定值。 从起点（A）开始遍历，找到子节点（B），更新子节点的权重：min(A的权重+A到B边的权重,B节点权重) 循环上面的步骤一直更新所有节点 时间复杂度O(nm) 将图的顶点数设为 n、边数设为 m。 该算法经过 n 轮更新操作后就会停止，而在每轮更新操作中都需要对各个边进行 1 次确认 因此 1 轮更新所花费的时间就是 O(m)，整体的时间复杂度就是 O(nm) Java代码实现 贝尔曼-福特算法 狄克斯特拉算法 解决的问题 狄克斯特拉(Dijkstra)算法也是求解最短路径问题 的算法，使用它可以求得从起点到终点的路径中权重总和最小的那条路径。 求解的步骤 首先设置各个顶点的初始权重 :起点为 0，其他顶点为无穷大(∞)；这个权重的意思是从起点到当前节点的最短路径暂定值。 从起点出发，寻找可以从目前所在的顶点直达且尚未被搜索过的顶点。 计算各个候补顶点的权重。计算方法是“目前所在顶点的权重+目前所在顶点到候补顶点的权重”。 如果计算结果小于候补顶点的值，就更新这个值。 从候补顶点中选出权重最小的顶点，作为下一个被搜索的点，这一点与贝尔曼-福特算法不一样 时间复杂度 将图的顶点数设为 n、边数设为 m，那么如果事先不进行任何处理，该算法的时 间复杂度就是 O(n2)。 不过，如果对数据结构进行优化，那么时间复杂度就会变为 O(m + nlogn)。 Java代码实现 狄克斯特拉(Dijkstra)算法 贝尔曼福特算法和迪克斯特拉算法对比 说明 如果在一个闭环中边的权重总和是负数，那么只要不断遍历这个闭环，路径的权重就能不断减小，也就是说根本不存在最短路径。 贝尔曼 - 福特算法可以直接认定不存在最短路径，但在狄克斯特拉算法中，即便不存在最短路径，它也会 算出一个错误的最短路径出来。因此，有负数权重时不能使用狄克斯特拉算法。 总的来说，就是不存在负数权重时，更适合使用效率较高的狄克斯特拉算法，而存 在负数权重时，即便较为耗时，也应该使用可以得到正确答案的贝尔曼 - 福特算法。 A*（A-Star）算法 解决的问题 A-Start算法也是解决在图中求解最短路径问题的算法，由狄克斯特拉算法发展而来。 狄克斯特拉算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。 也就是说，一些离终点较远的顶点的最短路径也会被计算出来，但这部分其实是无用的。 与之不同，A* 就 会预先估算一个值，并利用这个值来省去一些无用的计算 第五章 安全算法 安全和算法 传输数据时的四个问题 窃听 A 向 B 发送的消息可能会在传输途中被 X 偷看(如下图)。这就是“窃听”。 假冒 A 以为向 B 发送了消息，然而 B 有可能是 X 冒充的(如下图);反过来，B 以为从 A 那里收到了消息，然而 A 也有可能是 X 冒充的。 篡改 即便 B 确实收到了 A 发送的消息，但也有可能像右图 这样，该消息的内容在途中就被 X 更改了。 除了被第三者篡改外，通 信故障导致的数据损坏也可能会使消息内容发生变化。 事后否认 B 从 A 那里收到了消息，但作为消息发送者的 A 可 能对 B 抱有恶意，并在事后声称“这不是我发送的消息”。 解决这些问题的安全技术 为了应对“窃听”，我们会使用“加密” 技术。 为了应对“假冒”，我们会使用“消息认证码”(下图左)或“数字签名”(下图右)技术。 为了应对“篡改”，我们同样会使用 “消息认证码”或“数字签名”技术。 其中“数字签名”技术还可以用于预防“事后否认”。 哈希函数 哈希函数可以把给定的数据转换成固定长度的无规律数值。 转换后的无规律数值可以作为数据摘要应用于各种各样的场景。 希函数的特征： 第一个特征是输出的哈希值数据长度不变。（不论输入的参数长短，得到的哈希值是定长的） 第二个特征是如果输入的数据相同，那么输出 的哈希值也必定相同。 第三个特征是即使输入的数据相似，但哪怕它们只有一比特的差别，那么输出的哈希值也会有很大的差异。 第四个特征是即使输入的两个数据完全不同，输 出的哈希值也有可能是相同的；这种情况叫作“哈希冲突”。 第五个特征是不可能从哈希值反向推算出原本的数据。（输入和输出不可逆） 哈希函数的算法中具有代表性的是 MD5 1、SHA-1 2和 SHA-2 等。其中 SHA-2 是现 在应用较为广泛的一个，而 MD5 和 SHA-1 存在安全隐患，不推荐使用。 应用示例 将用户输入的密码保存到服务器时也需要用到哈希函数。 如果把密码直接保存到服务器，可能会被第三者窃听，因此需要算出密码的哈希值，并只存储哈希值。 当用户输入密码时，先算出该输入密码的哈希值，再把它和服务 器中的哈希值进行比对。 共享密钥加密（对称加密） 共享密钥加密是加密和解密都使用相同密钥的一种加密方式。 实现共享密钥加密的算法有凯撒密码、AES 1、DES 2、动态口令等，其中 AES 的应用最 为广泛。 存在密钥分配问题 如上图，如果在A给B发送密钥时，被X监听了，则X就能用相同的密钥解密截获的密文。 公开密钥加密（非对称加密） 公开密钥加密是加密和解密使用不同密钥的一种加密方法。 由于使用的密钥不同，所以这种算法也被称为“非对称加密”。 加密用的密钥叫作“公开密钥”，解密用的叫作“私有密钥”。 实现公开密钥加密的算法有 RAS 算法、椭圆曲线加密算法等，其中使用最为广泛的是 RSA 算法。 不存在密钥分配问题 公开密钥和密文都是通过互联网传输的，因此可能会被 X 窃听。 但是，使用公开密钥无法解密密文，因此 X 也无法得到原本的数据。 密钥数量不会过多 只需要生成一对公私钥，就可以把公钥共享给n个人使用。 对称加密就的密钥数量会随着人的增多而增多。 公开密钥加密存在公开密钥可靠性的问题 如下图，加入B在把公钥Pb共享给A的时候，被X截获了；X把自己的公钥Px发送给了A。 这时A在不知情的情况下使用Px对数据进行加密发送给B时，X截获密文就可以通过私钥Sx进行解密。 然后X可以截获的通过公钥Pb加密恶意数据发送给B，B能够使用自己的密钥Sb进行解密，以为数据是A发送的。 如下图所示： 非对称加密算法的条件 可以使用某个数值对数据进行加密(计算)。 使用另一个数值对加密数据进行计算就可以让数据恢复原样。 无法从一种密钥推算出另一种密钥。 混合加密 共享密钥加密存在无法安全传输密钥的密钥分配问题，公开密钥加密又存在加密解密速度较慢的问题。 在混合加密中，要用处理速度较快的共享密钥加密对数据进行加密。不过，加密时使用的密钥，则需要用没有密钥分配问题的公开密钥加密进行处理。混合加密可以拆分成下面两步操作： 1、A在给B发送数据之前，先使用非对称的公钥对”对称加密的密钥“进行加密，然后把加密后的密文发送给A，A解密后就得到了”对称加密的密钥“。如下图： 2、发送数据时，A使用”对称加密的密钥“对数据进行加密，然后发送给B，这样B就能使用之前收到的”对称加密的密钥“对数据进行解密。如下图： 迪菲 - 赫尔曼密钥交换 迪菲 - 赫尔曼(Diffie-Hellman)密钥交换是一种可以在通信双方之间安全交换密钥的方法。 这种方法通过将双方共有的秘密数值隐藏在公开数值相关的运算中，来实现双方之间密钥的安全交换。 算法的概念 假设有一种方法可以合成两个密钥。使用这种方法来合成密钥P和密钥S，就会得到由这两个密钥的成分所构成的密钥 P-S。 这种合成方法有三个特征。 第一，即使持有密钥 P 和合成的密钥 P-S，也无法把密钥 S 单独取出来。 第二，不管是怎样合成而来的密钥，都可以把它作为新的元素，继续与别的密钥进行合成。如下图，使用密钥 P 和密钥 P-S，还能合成出新的密钥 P-P-S。 第三，密钥的合成结果与合成顺序无关，只与用了哪些密钥有关。比如合成密钥 B 和密钥 C 后，得到的是密 钥 B-C，再将其与密钥 A 合成，得到的就是密钥 A-B-C。而合成密钥 A 和密钥 C 后，得到的是密钥 A-C， 再将其与密钥 B 合成，得到的就是密钥 B-A-C。此处的密钥 A-B-C 和密钥 B-A-C 是一样的。 密钥的交换 消息认证码，MAC（Message Authentication Code） 消息认证码可以实现“认证”和“检测篡改”这两个功能。 举个例子，如下图，假设 A 发送给 B 的密文（abc）在通信过程中被 X 恶意篡改了，而 B 收到密文后没有意识到这个问题。 B对密文进行解密可能无法解密或者解密后的数据是xyz。如果A在向B进行商品订购，如果B解密出的密文是xyz，就会给A发送xyz商品从而导致问题。 如何使用消息认证码解决篡改问题呢？ A在发送数据之前，先生成一个用于制作消息验证码的密钥（key），然后用安全的方法（如混合加密）发送给B A对数据进行加密，并且使用第一步生成的key和密文生成一个数值，此值就是MAC A把MAC和密文一起发送给B B接收到密文和MAC后，先使用第一步A发送过来的key和密文使用同样的方法生成一个数值；并且使用此数值和收到的MAC进行比对 如果比对一致，则说明数据未被篡改 如果比对不一致，则说明数据被篡改了，直接丢弃数据；然后通知A重发 如果MAC和密文都被X截获了怎么办？ X可以修改密文，此时B使用被篡改后的密文和key生成的数值不等于MAC，就能确认通信过程中发生了篡改 X如果篡改了MAC，也与上一步一样，B也能确认通信过程中发生了篡改 X既篡改了密文也篡改了MAC，因为X没有生成MAC的key，所以B收到被篡改后的数据时同样能确认发生了篡改 我们可以把 MAC 想象成是由密钥和密文组成的字符串的“哈希值”。 计算 MAC 的算法有 HMAC 1、OMAC 2、CMAC 3等。目前，HMAC 的应用最为广泛。 消息验证码无法防止“事后否认” 然而，这种方法也有缺点。在使用消息认证码的过程中，AB 双方都可以对消息进行加密并且算出 MAC。 也就是说，我们无法证明原本的消息是 A 生成的还是 B 生成的。 因此，假如 A 是坏人，他就可以在自己发出消息后声称“这条消息是 B 捏造的”，而否认自己的行为。如果 B 是坏人，他也可以自己准备一条消息，然后声称“这是 A 发 给我的消息”。 数字签名 数字签名不仅可以实现消息认证码的认证和检测篡改功能，还可以预防事后否认问题的发生。 由于在消息认证码中使用的是共享密钥加密，所以持有密钥的收信人也有可能是消息的发 送者，这样是无法预防事后否认行为的。 而数字签名是只有发信人才能生成的，因此使用它就可以确定谁是消息的发送者了。 数字签名的特征 比如A给B发送消息，那么数字签名必须满足下面两个条件： 只要发送的消息上有 A 的数字签名，就能确定消息的发送者就是 A。 B 可以验证数字签名的正确性，但无法生成数字签名。 如何实现数字签名 先回想一下非对称加密的流程，A给B发送消息时使用B提供的公钥进行加密，B使用自己的私钥进行解密。如下图： 那么我们把这个过程反过来，就可以做到数字签名，如下图： A 使用自己的私有密钥加密消息。加密后的消息就是数字签名。 A把数字签名和原始的数据都发送给B B接收到数字签名和数据后，使用A提供的公钥进行解密，并把解密后的数据和发送来的数据做比对 如果一致，则说明此消息是由A发送的，因为A的公钥只能解密经有A的私钥加密的数据 能够用 A 的公开密钥解密的密文，必定是由 A 生成的。因此，我们可以利用这个结论来确认消息的发送者是否为 A，消息是否被人篡改。 由于 B 只有公开密钥，无法生成 A 的签名，所以也预防了“事后否认”这一问题的 发生。 在使用此方式进行加密时，A使用自己的私钥加密的数据最好没有任何意义，只是用来验证发送着是否是A，并且没有被篡改。 数字证书 “公开密钥加密”和“数字签名”无法保证公开密钥确实来自信息的发送者。因此，就算公 开密钥被第三者恶意替换，接收方也不会注意到。 而数字证书，就能保证公开密钥的正确性。 如何使用数据证书发送公钥 A持有公开密钥Pa 和 A私有密钥 Sa ，现在想要将公开密钥PA发送给B，如何做呢？ A首先需要向认证中心 (Certification Authority， CA)申请发行证书，证明公开密钥PA 确实由自己生成 认证中心里保管着他们自己准备的公开密钥Pc和私有密钥 Sc A将公开密钥Pa 和包含邮箱信息的个人资料发送给认证中心 认证中心对收到的资料进行确认，判断其是否为A本人的资料。确认完毕后，认证中心使用自己的私有密钥 Sc，根据 A 的资料生成数字签名。 认证中心将生成的数字签名和资料放进同一个文件中，并把这个文件发送给 A。（这个文件就是 A 的数字证书） A 将作为公开密钥的数字证书发送给了 B。 B 收到数字证书后，确认证书里的邮件地址确实是 A 的地址。接着，B 获取了认证中心的公开密钥。 B 对证书内的签名进行验证，判断它是否为认证中心给出的签名。证书中的签名只能用认证中心的公开密钥 Pc 进行验证。如果验证结果没有异常，就能说明这份证书的确由认证中心发行。 确认了证书是由认证中心发行的，且邮件地址就是 A的之后，B从证书中取出A的公开密钥PA。这样，公开密钥便从 A 传到 了B。 经过以上步骤信息的接收者B可以确认公开密钥的制作者是A。 循环质疑，我们从认证中心获取的公钥Pc真的来自认证中心吗 由于公开密钥自身不能表示其制作者，所以有可能是冒充认证中心的 X 所生成的。也就是说，这里同样存在公开密钥问题(请参考下图)。 实际上，认证中心的公开密钥 PC 是以数字证书的形式交付的，会有更高级别的认证 中心对这个认证中心署名(请参考下图)。 所以我们有所怀疑可以一直验证下去。 最顶端的认证中心被称为“根认证中心”(root CA)，其自身的正当性由自己证明。 第六章 聚类 什么是聚类 将相似的对象分为一组 聚类就是在输入为多个数据时，将“相似”的数据分为一组的操作。1个组就叫作1个 “簇”。 下面的示例中每个点都代表 1 个数据，在平面上位置较为相近、被圈起来的点就代表一类相似的数据。 也就是说，这些数据被分为了 3 个簇。 如何定义“相似” 定义数据间的差距 根据数据类型不同，定义该数据是否“相似”的标准也不同。具体来说，就是要对两个数 据之间的“差距”进行定义。 如：假设某所高中的某个年级中共有 400 名学生，现在我们想要将这些学生在考试中取得的语 文、数学、英语成绩数据化，并将他们按照“擅长或不擅长的科目相似”进行聚类。 把每个学生都转换成“(语文成绩 , 数学成绩 , 英语成绩)”形式的数据后，就可以将两个数据(c1, m1, e1)和(c2, m2, e2)之间的差距定义为 (c1-c2) + (m1-m2) + (e1-e2) ，其中差距小的数据 就互为“相似的数据”。 符合条件的算法 即使定义好了数据间的差距，聚类的方法也会有很多种。我们可以设定各种各样的条件， 比如想把数据分为 10 个簇，或者想把 1 个簇内的数据定在 30~50 人之间，再或者想把簇内数据 间的最大距离设为 10，等等。而设定什么样的条件取决于进行聚类的目的。 k-means 算法 k-means 算法是聚类算法中的一种，它可以根据事先给定的簇的数量进行聚类。 k-means算法步骤 首先准备好需要聚类的数据，然后决定簇的数量（比如下面图示簇的数量为3）。 随机选择 3 个点作为簇的中心点。 计算各个数据分别和 3 个中心点中的哪一个点距离最近。 将数据分到相应的簇中。这样，3 个簇的聚类就完成了。 计算各个簇中数据的重心，然后将簇的中心点移动到这个位置。 重新计算距离最近的簇的中心点，并将数据分到相应的簇中。 重复执行“将数据分到相应的簇中”和“将中心点移到重心的位置”这两个操作，直到中心点不 再发生变化为止。 解说： k-means 算法中，随着操作的不断重复，中心点的位置必定会在某处收敛，这一点 已经在数学层面上得到证明。 前面的例子中我们将簇的数量定为 3，若现在使用同样的数据，将簇的数量定为 2， 那么聚类将如下图所示。 位于左边和下边的两个数据块被分到了一个簇中。就像这样，由于 k-means 算法需 要事先确定好簇的数量，所以设定的数量如果不合理，运行的结果就可能会不符合我们的需求。 如果对簇的数量没有明确要求，那么我们可以事先对数据进行分析，推算出一个合适的数量，或者不断改变簇的数量来试验 k-means 算法。 另外，如果簇的数量同样为 2，但中心点最初的位置不同，那么也可能会出现下图 这样的聚类结果。 与之前的情况不同，这次右上和右下的两个数据块被分到了一个簇中。也就是说， 即使簇的数量相同，只要随机设置的中心点最初的位置不同，聚类的结果也会产生变化。 因此，我们可以通过改变随机设定的中心点位置来不断尝试 k-means 算法，再从中选择 最合适的聚类结果。 补充说明 除了 k-means 算法以外，聚类算法还有很多，其中“层次聚类算法”较为有名。与 k-means 算法不同，层次聚类算法不需要事先设定簇的数量。 在层次聚类算法中，一开始每个数据都自成一类。也就是说，有 n 个数据就会形成 n 个簇。然后重复执行“将距离最近的两个簇合并为一个”的操作 n-1 次。每执行 1 次， 簇就会减少 1 个。执行 n - 1 次后，所有数据就都被分到了一个簇中。在这个过程中，每个阶段的簇的数量都不同，对应的聚类结果也不同。只要选择其中最为合理的 1 个结果 就好。 合并簇的时候，为了找出“距离最近的两个簇”，需要先对簇之间的距离进行定义。 根据定义方法不同，会有“最短距离法”“最长距离法”“中间距离法”等多种算法。 第七章 其他算法 欧几里得算法 欧几里得算法(又称辗转相除法)用于计算两个数的最大公约数**(GCD:greatest common divisor)**，被称为世界上最古老的算法。 使用欧几里得算法求1112和695的最大公约数 首先用较小的数字去除较大的数字，求出余数。也就是对两个数字进行 mod 运算，除完后的余数为417。 mod运算即取余运算，A mod B 就是算出A除以B后的余数C。 接下来再用除数695和余数417进行mod运 算。结果为 278。 继续重复同样的操作，对 417 和 278 进行 mod 运算，结果为139。 对 278 和 139 进行 mod 运算，结果为 0。也就 是说，278 可以被 139 整除。 余数为 0 时，最后一次运算中的除数 139 就是 1112 和 695 的最大公约数。 Java实现 欧几里得最大公约数算法 素性测试 素性测试是判断一个自然数是否为素数的测试。素数(prime number)就是只能被 1 和其自身整除，且大于 1 的自然数。 素数从小到大有 2、3、5、7、11、13…目前在加密技术中被广泛应用的 RSA 算法就会用到大素数，因此“素性测试”在该算法中起到了重要的作用。","categories":[],"tags":[]},{"title":"读书笔记-《你的第一本保险指南》","slug":"读书笔记-《你的第一本保险指南》","date":"2020-09-17T05:01:29.891Z","updated":"2020-09-17T05:01:29.892Z","comments":true,"path":"2020/09/17/读书笔记-《你的第一本保险指南》/","link":"","permalink":"https://nijixucai.github.io/2020/09/17/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E4%BF%9D%E9%99%A9%E6%8C%87%E5%8D%97%E3%80%8B/","excerpt":"","text":"1、破除误会，我们真的了解保险吗 我们对保险的认识：理赔似乎特别难 发生的事故不在保险范围，不能赔付 客户未如实告知自身情况，不能赔付 条款过于严苛，不能赔付 什么是核保师与健康告知 健康告知 健康告知问询 健康问询：是否有疾病或住院记录等 职业问询：是否从事高危行业 生活问询：是否吸烟、酗酒（酒精依赖），是否有极限运动等危险性高的业余爱好等 核保结论 结论一：标准体。恭喜，你完美地符合健康告知中的所有要求，可以直接投保，无须做补充告知 结论二：次标准体。可能有少数几条不符合健康告知，但考虑到基本在可接受范围内，保险公司就“勉为其难”地允许你投保了 接受除外责任：保险公司考虑到投保人当前的健康状况，将特定疾病排除在责任范围之外 增加保费 结论三：延期。保险公司考虑到你的某个健康问题，暂不接受你的本次投保申请，建议过一段时间再来试试 结论四：拒保 到底怎么健康告知？ 说实话，当保险公司把重疾险、医疗险这类保障型产品放到网上销售的时候，其实只是想卖给标准体客户。 至于次标准体和非标准体客户，对不起，这类产品不是为他们准备的。 买保险一定要返本吗？ 当你想要返还的时候，你到底想要什么 第一，拿回保费。如果没有发生保险事故，请把我交的保费还给我 第二，获得赔偿。既然我购买了保险，总归是希望能派上用场。 追求保费返还，切莫因小失大 反本保险一般会比不反本（消费型）保险更贵 在追求保费返还时，想一下自己购买保险的初心：当初你说要买保险的时候，到底是用来做什么的？保费和保额，哪个才是你的初心？ 非要拿到保费，不妨这样选择 提前给付型重疾险：身患重疾或不幸身故，哪个提前发生，都可给付赔偿，但是代价依然是支付更多保费 保障终身只是保险产品的一个功能设置，而不应被视为一个优点，因为你为此支付了更多的保费 保险公司会不会破产 保险公司会破产，却不会完蛋 保险公司破产时，人寿保险合同及责任准备金，必须转让给其他经营有人寿保险业务的保险公司 保险保障基金：来源是81家财险公司和88家寿险公司，保险公司每年需向其缴纳一定数额的资金，这也是被写进《保险法》的强制性要求。 政府在做的，是拼命预防保险公司破产 一家保险公司从计划成立之初，就不得不接受一系列监管。这些监管措施和规定就像一道道防火墙，确保公司在正确轨道上运转。 第一道防火墙是极高的公司设立标准 第二道防火墙是全面科学的偿付能力监管 所谓偿付能力，指的是当保险公司遭遇极端情况时，是否仍有能力履行赔付责任。每个年度和季度，保险公司的精算、财务等专业人士都会编制公司偿付能力报告，涉及一系列数学模型和压力测试 根据偿付能力情况，保险公司会得到从优到差的评级，包括A、B、C、D4个等级。评级可以在保险公司官网的“公开信息查询”栏目查到，我们将它视为判断保险公司是否“靠谱”的一个重要标志。长期来看，只要评级稳定在A和B的公司，我们都可以放心购买其产品 第三道防火墙是频率高、强度大的现场检查 监管部门会随时进驻保险公司总公司和分公司，通过调取档案、查询系统等方式实施现场检查 当然，上述的防火墙虽好，如果因为贪污腐败而让保险公司蒙混过关，这是我们无法改变的事情，暂时只能接受 如何选择一家保险公司？ 对比不同保险公司的投诉情况 监管部门每年都会对各家保险公司的投诉情况进行通报、评分，并发布在官网上（比如保监会官网） 销售人员口碑如何，信息技术实力如何（比如官网和手机软件的使用体验），客服电话能否快速接通，诸如此类 最重要的是保险产品的性价比 2、购前指南：买保险的正确方法 买保险和吃麦当劳是一样的，保险产品一般都是很多保险组成的。 一份保险计划通常由一款主险和若干款附加险构成，主险就像一位大哥，带着一帮作为附加险的小弟。 这种充分利用和客户接触的机会推销尽可能多的产品，是一种普遍的保险销售模式 但是有时候，单点比套餐更好，毕竟保险公司定的产品并非根据我们的需求定，附加险可能并非我们需要的。 责任的多少、保额的高低、期限的长短，这三大因素直接决定了保险产品的价格。 保额：真到用时方恨少 期限：从一天到一辈子 短期产品 保险期限不超过一年 以一年为一期计，产品的定价就要参考当下被保险人的年龄来计算了。30岁时购买，价格可能是100元；5年后，价格可能就会涨到400元。这种随年龄增加而上涨的定价策略，叫作自然费率。客户每年交的钱，只负责承担当年的风险。 长期产品 10年、20年甚至终身 定价方法遵循两个原则：一是均衡费率原则，二是保证费率原则 均衡费率，指的是保险公司将被保险人未来很长一段时间的风险，归并到一起进行定价，而不只是一年的风险 比如，保到70岁或保终身，投保人未来几十年的疾病发生率或者死亡率被累计后算出保费，再按照20年或30年交费的方式进行均摊，价格就确定了 在这样一种模式下，长期产品的停售只意味着不接受新客户的购买，但并不影响已经投保的客户 保证费率：指的是在你投保的一瞬间，价格便已确定，后期不会增加。对于长期重疾险来说，即使投保人未来的发病率上升，保险公司也不会涨价 长期产品和短期产品费用比较 整体来看，购买短期险费用要比长期险费用高 人到中年，就有可能无法购买短期险 人到老年，则根本不能购买短期险 对于已经有长期险庇护的人来说，额外购买一份一年期产品，可以在一定时间内增加保额 短期险在年轻时比较便宜 保险产品的价格由谁决定 我们有哪些需求需要保险解决？ 得了重疾，有钱治病 得了重疾，弥补治疗期间的收入 不幸身故，给爸妈留一笔养老费 意外受伤，解决医保不包含的费用 保险这种产品不是一次性的，它是陪伴你度过漫长人生的一种风险规划 如何与保险业务员打交道 保险公司会不遗余力地增加产品的“人情味”，比如将保险塑造成爱与责任的象征，让你把对子女、父母的爱寄托于保险产品之上，让购买行为更加顺理成章 保险销售人员到底指的是谁 第一，保险代理人。全国约800万，他们代表各自所在的保险公司，只销售某一家保险公司的产品。 第二，保险经纪人。和代理人最大的不同是，经纪人代表的不是某一家保险公司，而是保险中介公司，他们可以销售多家保险公司产品 第三，银行理财经理 第四，互联网第三方平台 和业务员打交道，要遵循两个原则 想一下我们有时候会不会因为下面的情况而买保险 第一，卖保险的人是亲戚，抹不开面子，买吧。 第二，邻居都给孩子买的这个，我也买一个吧 第三，他答应我把佣金返还给我，省了不少钱，买吧。 第四，小伙子口才好，人也帅，卖的保险不会差。 第五，就算被骗一年才损失1000多块钱，买吧 好面子、从众心理、贪图小便宜、忽略产品的本质，这类问题经常发生，也间接催生了一批不靠谱的保险业务员 第一个原则：互相尊重，学会提问。 条款能给我看一下吗？ 为什么我需要这款产品？ 为什么这类产品你们家的最好？ 能比较一下不同产品吗？ 为什么要保终身？ 为什么这个附加险值得购买？ 如果你发现这位保险业务员面对你提出的一个个问题，要么答不出来，要么逻辑混乱，要么不分青红皂白地敌视及贬损其他保险公司，最好立即更换业务员 第二个原则：充分信任，要有主见 卖保险简单吗 产品贵不贵（同类产品的定价和费率对比）？ 到底有哪些保障（保险责任的解读）？ 退保能拿到多少保费（保单现金价值的解读）？ 买完后哪些信息可以修改（对保单保全功能的讲解）？ 这个产品能实现多高收益（如何计算分红险、万能险、年金等产品的投资收益）？ 缴费期限怎么选择（现金流贴现原理）？ 保险条款里有没有所谓的坑（除外责任做重点说明）？ 遇到纠纷的时候如何处理？ 如果他真的做了产品对比，但如果他推销的产品价格没有竞争力，该怎么办？他真的算清楚了产品收益，但客户觉得收益率不如想象的那么高，该怎么办？他真的一条一条地解释清楚除外责任，客户却产生“保险公司推卸责任”的情绪化误解，该怎么办？他因为客户的健康问题而拒绝其投保，之前的工作不就白忙活了吗？ 这些假设似乎暗示了保险销售人员“能力越强越卖不出去产品”的观点，但我想表达的绝不是“知识无用论”，它们只是在一定程度上反映了当前保险销售领域存在的弊病。而这些极端的例子恰恰凸显了“你”的重要性。 你的公司给你买保险了吗 企业团体保险 团险通常由4个保险产品组成： 定期寿险 重大疾病险 意外险 医疗险 团险计划可以涵盖以下责任： 罹患重大疾病：保额50万元（重大疾病险的重疾责任50万元）。 疾病导致身故：保额50万元（定期寿险身故责任50万元）。 意外导致身故：保额150万元（定期寿险身故责任50万元+意外险身故责任100万元）。 门诊责任：保额2万元（医疗险包含的门急诊医疗责任2万元）。 住院责任：保额30万元（医疗险包含的住院医疗责任30万元）。 团险价格之所以“亲民”，主要原因如下： 第一，团险可以简单类比为团购，买的人数多，节省了一部分管理成本，自然就能获得一定的优惠 第二，团险的主要销售对象是企业人力资源部，只要负责人拍板，100个员工就直接购买了，不用一个一个地宣传、介绍，间接降低了产品的销售费用，最终的实惠落在了每一位参保员工身上 第三，以企业名义投保，参保人员的工作环境和性质相对一致，外部风险可控，何况不少企业还有入职体检，可以很好解决客户的逆选择和健康问题 团险带来的“保险幻觉” 一般公司团险的保险产品的保障期限都是一年，如果完全依赖公司保险，我们一旦离职就会面临保险“裸奔”的情况 所以，建议大家用客观的态度看待公司为员工购买的团险。它是一种极好的员工福利，它应该是员工自身已购保险的有力补充，却不能被当作全部。 了解公司的团险政策 这份团险计划里有涵盖身故责任的产品吗？ 如果有，保额是多少？ 如果员工获得晋升，保额会随之提高吗？ 03 重点关注：中产必备的“四大保险金刚” 重大疾病险：为了不被改变的人生 重疾险的诞生，本质上是为了解决收入中断的风险，站在患者及其家人的角度，为已在重病深渊的家庭提供雪中送炭般的经济补偿 重疾险究竟保什么 什么叫“重大疾病”？ 保监会安排中国保险行业协会和中国医师协会，在2007年拿出了一版25种重疾标准，囊括所有高发重疾类型（其实，只要是重疾险就都包括这25种） 保监会设定的这25种重大疾病，其发生概率超过95%的疾病种类。 所以如果一个保险说他包含更多的重疾，然后让我们多花钱买它，其实没有太必要。 什么叫“罹患”？ 第一，病情达到某个标准，相当于确诊即赔，比如恶性肿瘤 第二，投保人为治疗某种疾病而接受了某种治疗方法。比如心脏瓣膜手术 第三，某种状态持续了一段时间。比如脑中风后遗症 除了重大疾病，重疾险还保这些 当重疾险的责任只有重大疾病时，消费者理所当然地提出了一个振聋发聩的问题：如果我一辈子没得重疾，这保费岂不是白交了？ 好，为了不让你白交，保险公司索性增加了很多其他责任，“顺便”提升了保费。买卖双方都高兴，这种商业模式堪称完美。 在新增的责任里，第一类是“身故责任”。这种包含身故责任的重疾险，基本上都可以“提前给付”。 这里的提前指的是重疾、身故二者中哪个先发生，就给付哪个。 提前给付不过是一种产品设计罢了，千万别觉得它是一项独特的优势。 第二类新增责任是轻症和中症责任 第三类新增责任是针对重大疾病的花样赔付方式。比如重疾和轻症可以赔付多次，又比如挑出某几个病种额外赔付50%的保额，再比如投保后前10年享受保额额外增加50%。 上面说的这些都是在增加保费的基础上增加了更多的责任，所以当保险公司说我们保的多的时候除非和别人价格一样，否则只是在骗我们花更多钱而已。 重疾险的保额及其他 如何确定保额 患重疾后，患者普遍面临的是3~5年的治疗康复期 与此同时，重疾导致收入中断将为家庭带来更大的压力 因此，重疾险的保额应至少覆盖投保人3~5年的收入 如年收入20万元的保额应该在60万以上 而且只要确保这款重疾险能提供60万元的重疾保额，有没有身故责任、多次赔付、投保人豁免，都无关紧要 重疾险应该保障多久和交多少年保费。 讨论这个问题有一个前提：我们选择的是长期产品。 对于重疾险、定期寿险，可以保终身或者保到70岁左右的长期产品，是我们的首选——不仅价格更划算，也不会出现保险中断的情况。 长期重疾险的缴费期往往有多种选择： 趸交（一次性交完） 10年交 20年交 少数产品甚至还设计了30年交 保障期限： 保障期限的延长，会带来保费的升高；没办法，一个人年龄越大，罹患重疾的概率就越高。如果预算充足，保终身当然是最好的选择。 在确保保额充足的情况下，我们可以把保额拆成两个产品来实现，一个保到退休，另一个保终身 如：对于需要60万元重疾险保额的小王来说，可以选择买一份保终身的30万元保额的重疾险，再买一份保到70岁的30万元保额的重疾险。这比直接购买一份保终身的60万元保额的重疾险，花费更少 定期寿险：解决人生中最大的风险 谁适合买寿险 如果说重疾险的赌注是病，寿险的赌注就是命。定期寿险赌的则是一段时间的命。比如投保人于30年内身故，受益人即可获得理赔款。 一般的定期寿险，除了保障身故，还会把全残也视作与身故等同的责任。 单身的人理应关心父母的养老问题 新婚的人会增加对另一半的考虑 有了孩子后，责任更重 意外险和寿险对比 这里需要额外强调一点。谈到身故风险，很多人会联想到意外险，因为它不是也有身故保障吗？ “疾病”和“意外”为占比最大的两类死亡原因，分别为79.3%和18.9%。 所以，单纯购买意外险，是无法解决身故的风险的。 如何选购定期寿险？ 确定保额是关键性的第一步 保额的高低，决定了投保人身故后他的妻子、父母或者孩子能拿到多少补偿。定期寿险的保额，主要取决于三个因素。 一是个人和家庭的债务额度，比如房贷、车贷等，确保一方身故后，债务不转嫁到另一方或父母身上 二是家庭成员的基本生活成本。如果家庭每年的开销为20万元，那么身故理赔金至少应为100万元，以负担家庭未来5—10年的基本生活开销。 三是父母的养老支出，这笔费用的计算逻辑和上一个类似。 定期寿险还要考虑的问题是保障期限 到底要保到多大年龄呢？我个人建议，以退休年龄为标准，60岁或70岁皆可。 至于缴费年限的选择，我建议尽可能拉长，20年交或30年交皆可。缴费年限越长，年均保费越低，从而做到用尽可能少的钱去撬动尽可能高的保额。 保额、保障期限和缴费年限都确定后，我们在选购具体产品时，还要格外关注三个方面： 第一，核保是否宽松。这是最重要的，因为如果健康告知非常严格，想买也买不了，何谈其他？比如，有的定期寿险不接受乙肝小三阳患者，有的不接受高危职业从业者。所以我们一定要弄清楚投保要求再买，尽量避免理赔时的潜在纠纷，才能真正做到安心。 第二，除外责任多不多。前文在分析如何阅读保险条款的时候，专门强调要关注除外责任。比如，有的定期寿险明确指出，因为战争、军事暴乱导致的死亡，它们概不负责。那么，对于去中东、非洲等地区旅游或工作的中国人来说，这种定期寿险就得慎重考虑购买了。 第三，价格低不低。如果上面几条标准比较起来都差不多，问题就变简单了：哪个产品便宜就选择哪个。 商业医疗险：让高额医疗开支不再可怕 社会医疗保险 在用医保卡看病的过程中，我们都接触过一些陌生的名词，比如起付线、药品目录、自费药、报销额度等。 起付线：的意思是，每年只有花到一定金额，才能开始报销，否则就都是自费 药品目录：指的是在医保系统中，对于医疗机构开具的药品做了不同分类，不同类型的药品报销额度也不一样，有的可全部报销，有的则只可报销一部分，还有的药全部要自费购买 销额度很好理解，即使药品、治疗等都在报销范围内，医保也不是无限制的报销，整体来看，每年的报销额度范围为20万~30万元；对于罹患重大疾病的患者来说，这一额度根本无法满足他们长期、昂贵的治疗需求。 医保不管的，让商业医疗保险来管 医疗险其实只包括两种产品 第一种是包含门诊责任的商业医疗保险，可暂且称之为门诊医疗保险 这种产品保额不高，一般是几千元。有的门诊医疗保险会设置一个免赔额，比如单次100元或者累计500元。免赔额和政府医保起付线是同一个概念，都是为了减少理赔支出，实际上也起到了降低保费的作用。 第二种是包含住院责任的商业医疗保险，我们称之为住院医疗保险。 这类产品的保额就高多了，几十万元甚至上百万元都很常见。和门诊医疗保险相比，住院医疗保险是下文要重点介绍的产品。 能被称作风险的，必然意味着财务上的巨大影响。所以和几十万甚至上百万元的医疗支出相比，几千元的门诊、住院费用，真的称不上风险。 买了重疾险，还要买医疗险吗 重疾险和商业医疗最重要的区别，是保险公司的理赔方式不一样 重疾险有点儿像一锤子买卖，只要符合条款规定，保险公司就会把理赔款一次性打给你，无论是几万元还是几十万元。 商业医保就不一样了，花多少才能赔多少，保额仅代表可报销额度的上限，而你不一定能花掉这么多钱 如果一个人罹患影响正常生活的重大疾病，那他主要面临的问题有两个：一是治疗费用太高，掏空家底；二是无法继续工作，失去收入。前者可以靠商业医疗保险解决，后者则只能靠重疾险解决，两类保险的功能不一样。 重疾险和商业医疗保险在定价方面的区别 长期重疾险每年的保费是恒定的，商业医疗保险的保费则会随着被保险人年龄的增加而上调 重疾险和商业医疗保险在续保方面的区别 目前市场上大多数医疗险都是一年期产品，如果第二年你想继续投保，得先看看保险条款是怎么规定的，通常有以下两种情况： 第一种是，卖不卖给你，我说了算。投保人的续保申请须经保险人审核同意，投保人申请续保时，保险人有权对费率进行调整。 第二种规定是，只要这个产品还在销售，保险公司就肯定会卖给你。连续投保时，保险人不会因为某一被保险人的健康状况变化或历史理赔情况而单独调整该被保险人的连续投保费率。 意外险：不容忽视的“小”保险 意外险保什么、不保什么 遭受外来的、突发的、非本意的、非疾病的使身体受到伤害的客观事件。自然死亡、疾病身故、猝死、自杀及自伤均不属于意外伤害。 在每份意外险的保险条款里，你都能看到这样的描述。这段话表达了两层意思： 第一，外来的、突发的、非本意的、非疾病的使身体受到伤害的客观事件，属于意外； 第二，自然死亡、疾病身故、猝死、自杀及自伤，不属于意外。 除了猝死，意外险还有一些“不保”： 意外险通常不保高危职业从业者 除了特定人群“不保”，还有某类地区“不保”。关于意外医疗责任，保险条款中往往会有一个补充描述：只承担中华人民共和国国境内（不包括港澳台地区）医院产生的医疗费用和支出。 最后一个“不保”，是某些行为不保。被保险人从事潜水、跳伞、攀岩运动、探险活动、武术比赛、摔跤比赛、特技表演、赛马、赛车等高风险活动期间发生的意外，不在意外险的责任范围内 配置意外险的几条原则 原则一：必须涵盖意外医疗责任。 意外导致的结果无非两种：伤残和死亡。因此，意外险保障的责任有三个必选项：身故、伤残、医疗。 意外受伤后，我们最大的需求就是医疗费用补偿。考虑到很多意外产生的医疗费用医保都无法报销，意外险的医疗责任就更重要了。 至于意外医疗的保额，一两万就足够了。如果是一两万元都治不好的意外受伤，一定已经严重到需要做手术或者长期住院治疗了，这时理赔的责任就可以交给上文提到的住院医疗保险了。 另外，你可能听说过住院津贴或住院保险金，它的作用是，投保人每住一天院，保险公司就会支付给他几百元钱，主要是为了弥补住院期间的收入损失，颇为贴心，本质上也属于意外医疗的责任范围。住院津贴属于锦上添花型保险，而且要花钱购买，所以有没有都无所谓。 原则二：一般意外身故的保额应足够高。 在这里我要提醒大家注意某些保险公司的“套路”。当你看到一个类似于“百万身价意外险”的打折产品时，请一定弄清楚它所说的百万身价到底是什么意思。举个例子，有个产品页面是这么描述该产品的： 一般意外身故：10万元 航空意外身故：100万元 我更喜欢以下这类保险： 一般意外身故：100万元 航空意外身故：200万元 原则三：不同人群的意外险，侧重点不一样。 对于职场白领来说，意外险既要有足够的身故补偿（用于弥补家庭经济损失），也要保证受伤后有钱治疗； 但对于孩子和老人来说，身故补偿就没有医疗费用补偿重要，毕竟他们不是家里的顶梁柱。 因此，孩子和老人的意外险，应侧重于考虑提升意外医疗的保额，而没有必要追求意外身故的高保额。 原则四：保障时间一年就够了。 之前在介绍一年期产品特征的时候我提过，意外险和医疗险大多会设计成短期险，这样一来，就可以随时按照意外发生率和医疗成本的波动进行价格调整。因此，每年各家公司的意外险层出不穷，可能去年买的产品，到了明年就没什么竞争力了，这时直接换一家公司购买就好。由于意外险的几个基本责任都没有等待期这一说，所以可以做到无缝衔接。 04 优化配置：给保险升个级 像有钱人一样看病 高端医疗，高端在哪里？ 第一，保额更高。几十万元甚至几百万元的保额都是小菜一碟，从几千万元到不设限，高端医疗的保额完全超乎你的想象。 第二，医院更多、更高端。从三甲医院的特需部、国际部，到私立医院、国际医院，而且不限中国地区，从亚太地区到全球，基本覆盖所有类型的医疗机构。 第三，保障更全面。除了传统的门诊、住院两大块之外，高端医疗险还包含分娩、牙科、眼科、体检等责任，要知道，这些治疗通常都在常规医疗险的除外项目里，一般医疗险都不管。 第四，增值服务更多。 第五，理赔体验更好。 保险能为我的养老做什么？ 该不该买养老保险？ 可不可以把保险当作投资方式 要回答上面两个问题，需要使用excel中的IRR公式计算内部收益率，如果内部收益率能够达到预期并且现在手头有钱就可以买。 比如年复利6%以上就能达到预期，否则不如买债券基金或者指数型基金。 该去香港买保险吗？ 略 05 个性化定制：保险方案，你自己说了算 如何给孩子买保险 先别着急买商业保险 和大人一样，孩子也是可以参加政府医保的。在配置商业保险之前，父母一定要参考当地的医保政策为孩子办理少儿医保。 少儿医保本质上是针对儿童罹患重大疾病提供的风险保障。 有没有医保也会影响孩子投保商业保险的价格。尤其是医疗险，被保险人有医保的医疗险价格更低。 孩子会面临哪些风险 风险一：身患危重疾病 孩子一旦患危重疾病，除了需要长期投入高额治疗费用，父母也可能为了照顾孩子而辞掉工作。 因此，重疾险和高保额住院医疗险是应该首先为孩子配置的保险。 重疾险的价值在于，罹患重疾后一次性获得定额赔偿，可作为自费治疗费用和家庭收入中断的补偿。 高额住院医疗险的价值在于应对高额的医疗费用，尤其是许多医保范围外的自费项目 风险二：发生意外受伤 风险三：身患一般疾病 配置儿童商业保险 孩子不该买哪些保险 包含身故责任的意外险不在我们的讨论范围内 定期寿险、终身寿险也无需购买 除意义不大的身故责任外，为孩子购买教育金、养老金，优先级也不高 孩子真正需要的商业保险其实只有三款：重大疾病险、意外险、高额住院医疗险。 关于孩子的重疾险 请记住一个事实：少儿罹患重大疾病的概率非常低。这直接决定了儿童重疾险的价格十分便宜。因此，为孩子配置重疾险，一定要抓住价格优势，尽可能提高保额，拉长期限。都是100万元的终身重疾险保额，30多岁男性的购买价格，可以达到小孩子的两倍多。 孩子的重疾险应该买保终身或者70岁的，不要买保障30年，三十年之后孩子才三、四十岁，那时断保再新买保险会更贵。 孩子最好的保险是父母 父母自身的健康以及稳定、持续的赚钱能力，是孩子最重要的保险。 总结一下为孩子配置保险的几个关键点。 作为父母，先把自己的保险配置好，因为你才是孩子最大的“保险”； 在购买任何商业保险之前，先为孩子办理好当地的少儿医保，这是政府给予的福利，一定要充分利用； 结合自身预算，首先配置高保额的重大疾病险和住院医疗险，其他的保险则量力购买。 如何给父母买保险 一个不断妥协退让的过程 其实父母面临的风险非常简单，就是疾病引发的财务风险。 这样看来，给父母配置保险，主要考虑的应该是重疾险、医疗险和意外险。 年龄超过60岁的人想要投保重疾险和医疗险会有很多限制： 第一，年龄限制。 几乎所有重疾险和医疗险的投保年龄都在0~60岁。对重疾险而言，55岁的投保年龄上限是普遍规则。 第二，保额限制。 同样一份保险，30岁的人和50岁的人可享受的保额上限是不一样的。 以重疾险为例，如果在网上直接投保，30岁的被保险人的保额上限基本为50万~60万元，而50岁的被保险人的保额上限只有10万元。 第三，保费倒挂。 一位55岁的男性购买保额为10万元的重疾险，每年需要交3500元左右，交20年，总计7万元的支出和10万元的保额相比，差别不大。 第四，健康告知不符。 患有高血压、心脏病、糖尿病的老年人，可以直接和重大疾病险、住院医疗险说再见了 保险公司也意识到了这个问题，于是想了一个办法：双方各退一步。保险公司把保障范围缩小，限制也随之减少。但这个保障范围不能太小，得有存在的意义。 于是，防癌类保险应运而生。重疾险涵盖的几十种疾病，只保留第一项，即恶性肿瘤；住院医疗险涵盖的所有疾病的住院责任，也只保留一项，即癌症住院责任。 这种做法最大的好处，就是健康告知的内容大幅减少。只要不是易引发癌症的症状（肝部疾病、器官或组织的结节等），保险公司都不介意，高血压、糖尿病患者也可以投保。毕竟，高血压导致的急性心梗和糖尿病导致的终末期肾病或截肢，都不在防癌类保险的责任范围内。 六分靠规划，四分靠心态 哪怕有那么多的限制，我们还是可以购买意外险、防癌险、防癌医疗险和糖尿病特定疾病重疾险。 如果你想简明扼要地掌握给父母买保险的技巧，请记住以下几点。 第一，确保父母双方都有社会医疗保险。不管是城市的居民医保，还是农村的“新农合”，没有的话，赶紧先把社会医保办好。 第二，遇到疑难杂症，不少人会选择带父母来北上广等大城市就诊。所以，请提前研究好医保的异地结算流程，确保不让医保“白交”，这一点非常有必要。 第三，详细了解爸妈的身体健康情况，对症下药买保险。 如何给自己买保险 18岁保险清单 学生团体保险：包含意外身故/伤残责任，意外医疗责任，住院医疗责任；预算为200元。 或自己投保： 意外险：包含意外身故/伤残责任，意外医疗责任；预算为200元（保额为50万元）。 医疗险：包含疾病导致的住院医疗责任，预算为200元。 18岁保障速览 身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 22岁新增保险情况 定期寿险A：受益人为父母，保额大约相当于父母5年的退休金；预算为每年500元（保额50万元，保障期30年，缴费期30年）。 保障速览 身故补偿（不限死亡原因）：50万元。 额外身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 28岁新增保险情况 定期寿险B：受益人为法定受益人，保额约等于5倍年薪； 预算为每年1000元（保额80万元，保到60岁，缴费期30年）。 重大疾病险A：保额约等于购买时的3倍年薪；预算为每年5000元（保额50万元，保到70岁，缴费期30年）。 28岁保障速览 身故补偿（不限死亡原因）：130万元。 额外身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 重大疾病补偿：50万元。 32岁新增保险情况 意外险：包含意外身故/伤残责任；预算为每年400元（保额100万元）。 减额定期寿险C：受益人为法定受益人，保额等于房贷总额；预算为每年2000元（保额150万元，保障期30年，缴费期20年）。（有房贷才买） 重大疾病险B：提升重疾保额；预算为每年5000元（保额30万元，保终身，缴费期30年）。 32岁保障速览 身故补偿（不限死亡原因）：130万元。 额外身故补偿（仅限意外原因）：150万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 重大疾病补偿：80万元。 34岁 意外险：包含意外身故/伤残责任，意外医疗责任；预算为每年200元（保额50万元）。 意外险：包含意外身故/伤残责任；预算为每年400元（保额100万元）。 医疗险：包含疾病导致的住院医疗责任；预算为每年200元。定期寿险A：受益人为父母，保额相当于父母5年的退休金；预算为每年500元（保额50万元，保障期30年，缴费期30年）。 定期寿险B：受益人为法定受益人，保额相当于自己5倍的年薪。预算为每年1000元（保额80万元，保到60岁，缴费期30年）。 减额定期寿险C：受益人为法定受益人，保额等于房贷总额；预算为每年2000元（保额150万元，保障期30年，缴费期20年）。 定期寿险D：受益人为子女，保额相当于孩子5年的生活费；预算为每年4000元（保额100万元，保到60岁，缴费期20年）。 重大疾病险A：保额相当于自己当时的3倍年薪；预算为每年5000元（保额50万元，保到70岁，缴费期30年）。重大疾病险B：提升重疾险保额；预算为每年5000元（保额30万元，保终身，缴费期30年）。 养老保险（60岁领取）：预算为每年60000元（每月5000元）。 给自己买保险，不能一蹴而就，应随着人生进入不同阶段而分步实施。在这个过程中，我们需要对自己的情感进行再分配，说到底就是，回答“为谁买保险”的问题。比如，涉及医疗补偿的保险（如住院医疗险、重大疾病险），是为了让自己不至于被疾病掏空腰包；再比如，涉及身故补偿的保险（如定期寿险、意外险），是为了让家人能够继续维持原来的生活水准。","categories":[],"tags":[]},{"title":"IDEA安装leetcode插件","slug":"others/IDEA安装leetcode插件","date":"2020-08-03T09:51:46.196Z","updated":"2020-08-12T02:46:49.302Z","comments":true,"path":"2020/08/03/others/IDEA安装leetcode插件/","link":"","permalink":"https://nijixucai.github.io/2020/08/03/others/IDEA%E5%AE%89%E8%A3%85leetcode%E6%8F%92%E4%BB%B6/","excerpt":"","text":"为什么安装leetcode插件 当然是刷题了，程序员都懂的。官方地址： 力扣 (leetcode) 官网 - 全球极客挚爱的技术成长平台 如何安装leetcode插件 安装IDEA插件 插件地址：leetcode editor；插件如何安装略。 配置插件 打开IDEA的Preferences，找到Tools-leetcode plugin；页面如下： 上图的序号配置依次如下： 配置leecode网站的用户名密码 配置生成代码的地址，此处我选择的是一个专门的项目的${base_dir}/src/main/java/com目录，此插件会自动在此路径下创建leetcode/editor/cn,所以最终代码会在${base_dir}/src/main/java/com/leetcode/editor/cn路径下 配置类名和文件名，必须配置默认是中文类名(需要勾选Costom Template) 贴出本人配置供参考： CodeFileName: 1P$&#123;question.frontendQuestionId&#125;$!velocityTool.camelCaseName($&#123;question.titleSlug&#125;) CodeTemplate: 12345package com.leetcode.editor.cn;$&#123;question.content&#125;public class P$&#123;question.frontendQuestionId&#125;$!velocityTool.camelCaseName($&#123;question.titleSlug&#125;)&#123; $&#123;question.code&#125;&#125; 如何使用leetcode插件 生成模板代码 1、按照下图标的顺序依次点击插件会加载各种算法 2、随便双击列表中的一个算法，会在配置的${base_dir}/src/main/java/com/leetcode/editor/cn路径下生成模板代码，效果如下： 结果验证 码完代码之后选中相应的算法点Submit来进行验证正确性 注意事项 1、下面的两个注释不能删除或修改 123// leetcode submit region begin(Prohibit modification and deletion)// leetcode submit region end(Prohibit modification and deletion) 2、提交的所有代码必须在自动生成的Solution类之内 非常感谢！！！","categories":[],"tags":[]}],"categories":[],"tags":[]}